{
  "url": "https://docs.cloud.google.com/vertex-ai/generative-ai/docs/model-reference/function-calling",
  "title": "Function calling reference  |  Generative AI on Vertex AI  |  Google Cloud Documentation",
  "text_content": "Home\nTechnology areas\nGenerative AI on Vertex AI\nDocumentation\nAPI reference\nSend feedback\nFunction calling reference\nStay organized with collections\nSave and categorize content based on your preferences.\nFunction calling improves the LLM's ability to provide relevant and contextual\nanswers.\nYou can provide custom functions to a generative AI model with the Function\nCalling API. The model doesn't directly invoke these functions, but instead\ngenerates structured data output that specifies the function name and suggested\narguments.\nThis output enables the calling of external APIs or information\nsystems such as databases, customer relationship management systems, and\ndocument repositories. The resulting API output can be used by the LLM to\nimprove response quality.\nFor more conceptual documentation on function calling, see\nFunction calling\n.\nSupported models\nGemini 2.5 Flash\n(Preview)\nGemini 2.5 Flash-Lite\n(Preview)\nGemini 2.5 Flash-Lite\nGemini 2.5 Flash with Live API native audio\n(Preview)\nGemini 2.0 Flash with Live API\n(Preview)\nGemini 2.5 Pro\nGemini 2.5 Flash\nGemini 2.0 Flash\nGemini 2.0 Flash-Lite\nLimitations\n:\nThe maximum number of function declarations that can be provided with the request is 128.\nExample syntax\nSyntax to send a function call API request.\ncurl\ncurl\n-X\nPOST\n\\\n-H\n\"Authorization: Bearer\n$(\ngcloud\nauth\nprint-access-token\n)\n\"\n\\\n-H\n\"Content-Type: application/json\"\n\\\nhttps://\n${\nLOCATION\n}\n-aiplatform.googleapis.com/v1/projects/\n${\nPROJECT_ID\n}\n/locations/\n${\nLOCATION\n}\n/publishers/google/models/\n${\nMODEL_ID\n}\n:generateContent\n\\\n-d\n'{\n\"contents\": [{\n...\n}],\n\"tools\": [{\n\"function_declarations\": [\n{\n...\n}\n]\n}]\n}'\nParameter list\nSee\nexamples\nfor implementation details.\nFunctionDeclaration\nDefines a function that the model can generate JSON inputs for based on\nOpenAPI 3.0\nspecifications.\nParameters\nname\nstring\nThe name of the function to call. Must start with a letter or an underscore. Must be a-z, A-Z, 0-9, or contains underscores, dots, or dashes, with a maximum length of 64.\ndescription\nOptional:\nstring\nThe description and purpose of the function. The model uses this to decide how and whether to call the function. For the best results, we recommend that you include a description.\nparameters\nOptional:\nSchema\nDescribes the parameters of the function in the OpenAPI JSON Schema Object format:\nOpenAPI 3.0 specification\n.\nresponse\nOptional:\nSchema\nDescribes the output from the function in the OpenAPI JSON Schema Object format:\nOpenAPI 3.0 specification\n.\nFor more information, see\nFunction calling\nSchema\nDefines the format of the input and output data in a function call based on the\nOpenAPI 3.0 Schema\nspecification.\nParameters\ntype\nstring\nEnum. The type of the data. Must be one of:\nSTRING\nINTEGER\nBOOLEAN\nNUMBER\nARRAY\nOBJECT\ndescription\nOptional:\nstring\nDescription of the data.\nenum\nOptional:\nstring[]\nPossible values of the element of primitive type with enum format.\nitems\nOptional:\nSchema[]\nSchema of the elements of\nType.ARRAY\nproperties\nOptional:\nSchema\nSchema of the properties of\nType.OBJECT\nrequired\nOptional:\nstring[]\nRequired properties of\nType.OBJECT\n.\nnullable\nOptional:\nbool\nIndicates if the value may be\nnull\n.\nFunctionCallingConfig\nThe\nFunctionCallingConfig\ncontrols the behavior of the model and\ndetermines what type of function to call.\nParameters\nmode\nOptional:\nenum/string[]\nAUTO\n: Default model behavior. The model can make predictions in either a function call form or a natural language response form. The model decides which form to use based on the context.\nNONE\n: The model doesn't make any predictions in the form of function calls.\nANY\n: The model is constrained to always predict a function call. If\nallowed_function_names\nis not provided, the model picks from all of the available function declarations. If\nallowed_function_names\nis provided, the model picks from the set of allowed functions.\nallowed_function_names\nOptional:\nstring[]\nFunction names to call. Only set when the\nmode\nis\nANY\n. Function names should match\n[FunctionDeclaration.name]\n. With mode set to\nANY\n, the model will predict a function call from the set of function names provided.\nfunctionCall\nA predicted\nfunctionCall\nreturned from the model that contains a string\nrepresenting the\nfunctionDeclaration.name\nand a structured JSON object\ncontaining the parameters and their values.\nParameters\nname\nstring\nThe name of the function to call.\nargs\nStruct\nThe function parameters and values in JSON object format.\nSee\nFunction calling\nfor parameter details.\nfunctionResponse\nThe resulting output from a\nFunctionCall\nthat contains a string representing the\nFunctionDeclaration.name\n. Also contains a structured JSON object with the\noutput from the function (and uses it as context for the model). This should contain the\nresult of a\nFunctionCall\nmade based on model prediction.\nParameters\nname\nstring\nThe name of the function to call.\nresponse\nStruct\nThe function response in JSON object format.\nExamples\nSend a function declaration\nThe following example is a basic example of sending a query and a function declaration\nto the model.\nREST\nBefore using any of the request data,\nmake the following replacements:\nPROJECT_ID\n: Your\nproject ID\n.\nMODEL_ID\n: The ID of the model that's being processed.\nROLE\n: The\nidentity of the entity\nthat creates the message.\nTEXT\n: The prompt to send to the model.\nNAME\n: The name of the function to call.\nDESCRIPTION\n: Description and purpose of the function.\nFor other fields, see the\nParameter list\ntable.\nHTTP method and URL:\nPOST https://aiplatform.googleapis.com/v1/projects/\nPROJECT_ID\n/locations/global/publishers/google/models/\nMODEL_ID\n:generateContent\nRequest JSON body:\n{\n\"contents\": [{\n\"role\": \"\nROLE\n\",\n\"parts\": [{\n\"text\": \"\nTEXT\n\"\n}]\n}],\n\"tools\": [{\n\"function_declarations\": [\n{\n\"name\": \"\nNAME\n\",\n\"description\": \"\nDESCRIPTION\n\",\n\"parameters\": {\n\"type\": \"\nTYPE\n\",\n\"properties\": {\n\"location\": {\n\"type\": \"\nTYPE\n\",\n\"description\": \"\nDESCRIPTION\n\"\n}\n},\n\"required\": [\n\"location\"\n]\n}\n}\n]\n}]\n}\nTo send your request, choose one of these options:\ncurl\nSave the request body in a file named\nrequest.json\n,\nand execute the following command:\ncurl -X POST \\\n-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n-H \"Content-Type: application/json; charset=utf-8\" \\\n-d @request.json \\\n\"https://aiplatform.googleapis.com/v1/projects/\nPROJECT_ID\n/locations/global/publishers/google/models/\nMODEL_ID\n:generateContent\"\nPowerShell\nSave the request body in a file named\nrequest.json\n,\nand execute the following command:\n$cred = gcloud auth print-access-token\n$headers = @{ \"Authorization\" = \"Bearer $cred\" }\nInvoke-WebRequest `\n-Method POST `\n-Headers $headers `\n-ContentType: \"application/json; charset=utf-8\" `\n-InFile request.json `\n-Uri \"https://aiplatform.googleapis.com/v1/projects/\nPROJECT_ID\n/locations/global/publishers/google/models/\nMODEL_ID\n:generateContent\" | Select-Object -Expand Content\nExample curl command\nPROJECT_ID\n=\nmyproject\nLOCATION\n=\nus-central1\nMODEL_ID\n=\ngemini-2.5-flash\ncurl\n-X\nPOST\n\\\n-H\n\"Authorization: Bearer\n$(\ngcloud\nauth\nprint-access-token\n)\n\"\n\\\n-H\n\"Content-Type: application/json\"\n\\\nhttps://\n${\nLOCATION\n}\n-aiplatform.googleapis.com/v1/projects/\n${\nPROJECT_ID\n}\n/locations/\n${\nLOCATION\n}\n/publishers/google/models/\n${\nMODEL_ID\n}\n:generateContent\n\\\n-d\n'{\n\"contents\": [{\n\"role\": \"user\",\n\"parts\": [{\n\"text\": \"What is the weather in Boston?\"\n}]\n}],\n\"tools\": [{\n\"functionDeclarations\": [\n{\n\"name\": \"get_current_weather\",\n\"description\": \"Get the current weather in a given location\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"location\": {\n\"type\": \"string\",\n\"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n}\n},\n\"required\": [\n\"location\"\n]\n}\n}\n]\n}]\n}'\nGen AI SDK for Python\nfrom\ngoogle\nimport\ngenai\nfrom\ngoogle.genai.types\nimport\nGenerateContentConfig\n,\nHttpOptions\ndef\nget_current_weather\n(\nlocation\n:\nstr\n)\n-\n>\nstr\n:\n\"\"\"Example method. Returns the current weather.\nArgs:\nlocation: The city and state, e.g. San Francisco, CA\n\"\"\"\nweather_map\n:\ndict\n[\nstr\n,\nstr\n]\n=\n{\n\"Boston, MA\"\n:\n\"snowing\"\n,\n\"San Francisco, CA\"\n:\n\"foggy\"\n,\n\"Seattle, WA\"\n:\n\"raining\"\n,\n\"Austin, TX\"\n:\n\"hot\"\n,\n\"Chicago, IL\"\n:\n\"windy\"\n,\n}\nreturn\nweather_map\n.\nget\n(\nlocation\n,\n\"unknown\"\n)\nclient\n=\ngenai\n.\nClient\n(\nhttp_options\n=\nHttpOptions\n(\napi_version\n=\n\"v1\"\n))\nmodel_id\n=\n\"gemini-2.5-flash\"\nresponse\n=\nclient\n.\nmodels\n.\ngenerate_content\n(\nmodel\n=\nmodel_id\n,\ncontents\n=\n\"What is the weather like in Boston?\"\n,\nconfig\n=\nGenerateContentConfig\n(\ntools\n=\n[\nget_current_weather\n],\ntemperature\n=\n0\n,\n),\n)\nprint\n(\nresponse\n.\ntext\n)\n# Example response:\n# The weather in Boston is sunny.\nNode.js\nconst\n{\nVertexAI\n,\nFunctionDeclarationSchemaType\n,\n}\n=\nrequire\n(\n'\n@google-cloud/vertexai\n'\n);\nconst\nfunctionDeclarations\n=\n[\n{\nfunction_declarations\n:\n[\n{\nname\n:\n'get_current_weather'\n,\ndescription\n:\n'get weather in a given location'\n,\nparameters\n:\n{\ntype\n:\nFunctionDeclarationSchemaType\n.\nOBJECT\n,\nproperties\n:\n{\nlocation\n:\n{\ntype\n:\nFunctionDeclarationSchemaType\n.\nSTRING\n},\nunit\n:\n{\ntype\n:\nFunctionDeclarationSchemaType\n.\nSTRING\n,\nenum\n:\n[\n'celsius'\n,\n'fahrenheit'\n],\n},\n},\nrequired\n:\n[\n'location'\n],\n},\n},\n],\n},\n];\n/**\n* TODO(developer): Update these variables before running the sample.\n*/\nasync\nfunction\nfunctionCallingBasic\n(\nprojectId\n=\n'PROJECT_ID'\n,\nlocation\n=\n'us-central1'\n,\nmodel\n=\n'gemini-2.0-flash-001'\n)\n{\n// Initialize Vertex with your Cloud project and location\nconst\nvertexAI\n=\nnew\nVertexAI\n({\nproject\n:\nprojectId\n,\nlocation\n:\nlocation\n});\n// Instantiate the model\nconst\ngenerativeModel\n=\nvertexAI\n.\npreview\n.\ngetGenerativeModel\n({\nmodel\n:\nmodel\n,\n});\nconst\nrequest\n=\n{\ncontents\n:\n[\n{\nrole\n:\n'user'\n,\nparts\n:\n[{\ntext\n:\n'What is the weather in Boston?'\n}]},\n],\ntools\n:\nfunctionDeclarations\n,\n};\nconst\nresult\n=\nawait\ngenerativeModel\n.\ngenerateContent\n(\nrequest\n);\nconsole\n.\nlog\n(\nJSON\n.\nstringify\n(\nresult\n.\nresponse\n.\ncandidates\n[\n0\n].\ncontent\n));\n}\nJava\nimport\ncom.google.cloud.vertexai.\nVertexAI\n;\nimport\ncom.google.cloud.vertexai.api.\nContent\n;\nimport\ncom.google.cloud.vertexai.api.\nFunctionDeclaration\n;\nimport\ncom.google.cloud.vertexai.api.\nGenerateContentResponse\n;\nimport\ncom.google.cloud.vertexai.api.\nSchema\n;\nimport\ncom.google.cloud.vertexai.api.\nTool\n;\nimport\ncom.google.cloud.vertexai.api.\nType\n;\nimport\ncom.google.cloud.vertexai.generativeai.\nChatSession\n;\nimport\ncom.google.cloud.vertexai.generativeai.\nContentMaker\n;\nimport\ncom.google.cloud.vertexai.generativeai.\nGenerativeModel\n;\nimport\ncom.google.cloud.vertexai.generativeai.\nPartMaker\n;\nimport\ncom.google.cloud.vertexai.generativeai.\nResponseHandler\n;\nimport\njava.io.IOException\n;\nimport\njava.util.Arrays\n;\nimport\njava.util.Collections\n;\npublic\nclass\nFunctionCalling\n{\npublic\nstatic\nvoid\nmain\n(\nString\n[]\nargs\n)\nthrows\nIOException\n{\n// TODO(developer): Replace these variables before running the sample.\nString\nprojectId\n=\n\"your-google-cloud-project-id\"\n;\nString\nlocation\n=\n\"us-central1\"\n;\nString\nmodelName\n=\n\"gemini-2.0-flash-001\"\n;\nString\npromptText\n=\n\"What's the weather like in Paris?\"\n;\nwhatsTheWeatherLike\n(\nprojectId\n,\nlocation\n,\nmodelName\n,\npromptText\n);\n}\n// A request involving the interaction with an external tool\npublic\nstatic\nString\nwhatsTheWeatherLike\n(\nString\nprojectId\n,\nString\nlocation\n,\nString\nmodelName\n,\nString\npromptText\n)\nthrows\nIOException\n{\n// Initialize client that will be used to send requests.\n// This client only needs to be created once, and can be reused for multiple requests.\ntry\n(\nVertexAI\nvertexAI\n=\nnew\nVertexAI\n(\nprojectId\n,\nlocation\n))\n{\nFunctionDeclaration\nfunctionDeclaration\n=\nFunctionDeclaration\n.\nnewBuilder\n()\n.\nsetName\n(\n\"getCurrentWeather\"\n)\n.\nsetDescription\n(\n\"Get the current weather in a given location\"\n)\n.\nsetParameters\n(\nSchema\n.\nnewBuilder\n()\n.\nsetType\n(\nType\n.\nOBJECT\n)\n.\nputProperties\n(\n\"location\"\n,\nSchema\n.\nnewBuilder\n()\n.\nsetType\n(\nType\n.\nSTRING\n)\n.\nsetDescription\n(\n\"location\"\n)\n.\nbuild\n()\n)\n.\naddRequired\n(\n\"location\"\n)\n.\nbuild\n()\n)\n.\nbuild\n();\nSystem\n.\nout\n.\nprintln\n(\n\"Function declaration:\"\n);\nSystem\n.\nout\n.\nprintln\n(\nfunctionDeclaration\n);\n// Add the function to a \"tool\"\nTool\ntool\n=\nTool\n.\nnewBuilder\n()\n.\naddFunctionDeclarations\n(\nfunctionDeclaration\n)\n.\nbuild\n();\n// Start a chat session from a model, with the use of the declared function.\nGenerativeModel\nmodel\n=\nnew\nGenerativeModel\n(\nmodelName\n,\nvertexAI\n)\n.\nwithTools\n(\nArrays\n.\nasList\n(\ntool\n));\nChatSession\nchat\n=\nmodel\n.\nstartChat\n();\nSystem\n.\nout\n.\nprintln\n(\nString\n.\nformat\n(\n\"Ask the question: %s\"\n,\npromptText\n));\nGenerateContentResponse\nresponse\n=\nchat\n.\nsendMessage\n(\npromptText\n);\n// The model will most likely return a function call to the declared\n// function `getCurrentWeather` with \"Paris\" as the value for the\n// argument `location`.\nSystem\n.\nout\n.\nprintln\n(\n\"\\nPrint response: \"\n);\nSystem\n.\nout\n.\nprintln\n(\nResponseHandler\n.\ngetContent\n(\nresponse\n));\n// Provide an answer to the model so that it knows what the result\n// of a \"function call\" is.\nContent\ncontent\n=\nContentMaker\n.\nfromMultiModalData\n(\nPartMaker\n.\nfromFunctionResponse\n(\n\"getCurrentWeather\"\n,\nCollections\n.\nsingletonMap\n(\n\"currentWeather\"\n,\n\"sunny\"\n)));\nSystem\n.\nout\n.\nprintln\n(\n\"Provide the function response: \"\n);\nSystem\n.\nout\n.\nprintln\n(\ncontent\n);\nresponse\n=\nchat\n.\nsendMessage\n(\ncontent\n);\n// See what the model replies now\nSystem\n.\nout\n.\nprintln\n(\n\"Print response: \"\n);\nString\nfinalAnswer\n=\nResponseHandler\n.\ngetText\n(\nresponse\n);\nSystem\n.\nout\n.\nprintln\n(\nfinalAnswer\n);\nreturn\nfinalAnswer\n;\n}\n}\n}\nGo\nimport\n(\n\"context\"\n\"fmt\"\n\"io\"\ngenai\n\"google.golang.org/genai\"\n)\n//\ngenerateWithFuncCall\nshows\nhow\nto\nsubmit\na\nprompt\nand\na\nfunction\ndeclaration\nto\nthe\nmodel\n,\n//\nallowing\nit\nto\nsuggest\na\ncall\nto\nthe\nfunction\nto\nfetch\nexternal\ndata\n.\nReturning\nthis\ndata\n//\nenables\nthe\nmodel\nto\ngenerate\na\ntext\nresponse\nthat\nincorporates\nthe\ndata\n.\nfunc\ngenerateWithFuncCall\n(\nw\nio\n.\nWriter\n)\nerror\n{\nctx\n:=\ncontext\n.\nBackground\n()\nclient\n,\nerr\n:=\ngenai\n.\nNewClient\n(\nctx\n,\n&\ngenai\n.\nClientConfig\n{\nHTTPOptions\n:\ngenai\n.\nHTTPOptions\n{\nAPIVersion\n:\n\"v1\"\n},\n})\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to create genai client: %w\"\n,\nerr\n)\n}\nweatherFunc\n:=\n&\ngenai\n.\nFunctionDeclaration\n{\nDescription\n:\n\"Returns the current weather in a location.\"\n,\nName\n:\n\"getCurrentWeather\"\n,\nParameters\n:\n&\ngenai\n.\nSchema\n{\nType\n:\n\"object\"\n,\nProperties\n:\nmap\n[\nstring\n]\n*\ngenai\n.\nSchema\n{\n\"location\"\n:\n{\nType\n:\n\"string\"\n},\n},\nRequired\n:\n[]\nstring\n{\n\"location\"\n},\n},\n}\nconfig\n:=\n&\ngenai\n.\nGenerateContentConfig\n{\nTools\n:\n[]\n*\ngenai\n.\nTool\n{\n{\nFunctionDeclarations\n:\n[]\n*\ngenai\n.\nFunctionDeclaration\n{\nweatherFunc\n}},\n},\nTemperature\n:\ngenai\n.\nPtr\n(\nfloat32\n(\n0.0\n)),\n}\nmodelName\n:=\n\"gemini-2.5-flash\"\ncontents\n:=\n[]\n*\ngenai\n.\nContent\n{\n{\nParts\n:\n[]\n*\ngenai\n.\nPart\n{\n{\nText\n:\n\"What is the weather like in Boston?\"\n},\n},\nRole\n:\n\"user\"\n},\n}\nresp\n,\nerr\n:=\nclient\n.\nModels\n.\nGenerateContent\n(\nctx\n,\nmodelName\n,\ncontents\n,\nconfig\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to generate content: %w\"\n,\nerr\n)\n}\nvar\nfuncCall\n*\ngenai\n.\nFunctionCall\nfor\n_\n,\np\n:=\nrange\nresp\n.\nCandidates\n[\n0\n]\n.\nContent\n.\nParts\n{\nif\np\n.\nFunctionCall\n!=\nnil\n{\nfuncCall\n=\np\n.\nFunctionCall\nfmt\n.\nFprint\n(\nw\n,\n\"The model suggests to call the function \"\n)\nfmt\n.\nFprintf\n(\nw\n,\n\"%q with args: %v\n\\n\n\"\n,\nfuncCall\n.\nName\n,\nfuncCall\n.\nArgs\n)\n//\nExample\nresponse\n:\n//\nThe\nmodel\nsuggests\nto\ncall\nthe\nfunction\n\"getCurrentWeather\"\nwith\nargs\n:\nmap\n[\nlocation\n:\nBoston\n]\n}\n}\nif\nfuncCall\n==\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"model did not suggest a function call\"\n)\n}\n//\nUse\nsynthetic\ndata\nto\nsimulate\na\nresponse\nfrom\nthe\nexternal\nAPI\n.\n//\nIn\na\nreal\napplication\n,\nthis\nwould\ncome\nfrom\nan\nactual\nweather\nAPI\n.\nfuncResp\n:=\n&\ngenai\n.\nFunctionResponse\n{\nName\n:\n\"getCurrentWeather\"\n,\nResponse\n:\nmap\n[\nstring\n]\nany\n{\n\"location\"\n:\n\"Boston\"\n,\n\"temperature\"\n:\n\"38\"\n,\n\"temperature_unit\"\n:\n\"F\"\n,\n\"description\"\n:\n\"Cold and cloudy\"\n,\n\"humidity\"\n:\n\"65\"\n,\n\"wind\"\n:\n`\n{\n\"speed\"\n:\n\"10\"\n,\n\"direction\"\n:\n\"NW\"\n}\n`\n,\n},\n}\n//\nReturn\nconversation\nturns\nand\nAPI\nresponse\nto\ncomplete\nthe\nmodel\n's response.\ncontents\n=\n[]\n*\ngenai\n.\nContent\n{\n{\nParts\n:\n[]\n*\ngenai\n.\nPart\n{\n{\nText\n:\n\"What is the weather like in Boston?\"\n},\n},\nRole\n:\n\"user\"\n},\n{\nParts\n:\n[]\n*\ngenai\n.\nPart\n{\n{\nFunctionCall\n:\nfuncCall\n},\n}},\n{\nParts\n:\n[]\n*\ngenai\n.\nPart\n{\n{\nFunctionResponse\n:\nfuncResp\n},\n}},\n}\nresp\n,\nerr\n=\nclient\n.\nModels\n.\nGenerateContent\n(\nctx\n,\nmodelName\n,\ncontents\n,\nconfig\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to generate content: %w\"\n,\nerr\n)\n}\nrespText\n:=\nresp\n.\nText\n()\nfmt\n.\nFprintln\n(\nw\n,\nrespText\n)\n//\nExample\nresponse\n:\n//\nThe\nweather\nin\nBoston\nis\ncold\nand\ncloudy\nwith\na\ntemperature\nof\n38\ndegrees\nFahrenheit\n.\nThe\nhumidity\nis\n...\nreturn\nnil\n}\nREST (OpenAI)\nYou can call the Function Calling API by using the OpenAI library. For more information, see\nCall Vertex AI models by using the OpenAI library\n.\nBefore using any of the request data,\nmake the following replacements:\nPROJECT_ID\n: .\nMODEL_ID\n: The ID of the model that's being processed.\nHTTP method and URL:\nPOST https://aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/global/endpoints/openapi/chat/completions\nRequest JSON body:\n{\n\"model\": \"google/\nMODEL_ID\n\",\n\"messages\": [\n{\n\"role\": \"user\",\n\"content\": \"What is the weather in Boston?\"\n}\n],\n\"tools\": [\n{\n\"type\": \"function\",\n\"function\": {\n\"name\": \"get_current_weather\",\n\"description\": \"Get the current weather in a given location\",\n\"parameters\": {\n\"type\": \"OBJECT\",\n\"properties\": {\n\"location\": {\n\"type\": \"string\",\n\"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n}\n},\n\"required\": [\"location\"]\n}\n}\n}\n]\n}\nTo send your request, choose one of these options:\ncurl\nSave the request body in a file named\nrequest.json\n,\nand execute the following command:\ncurl -X POST \\\n-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n-H \"Content-Type: application/json; charset=utf-8\" \\\n-d @request.json \\\n\"https://aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/global/endpoints/openapi/chat/completions\"\nPowerShell\nSave the request body in a file named\nrequest.json\n,\nand execute the following command:\n$cred = gcloud auth print-access-token\n$headers = @{ \"Authorization\" = \"Bearer $cred\" }\nInvoke-WebRequest `\n-Method POST `\n-Headers $headers `\n-ContentType: \"application/json; charset=utf-8\" `\n-InFile request.json `\n-Uri \"https://aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/global/endpoints/openapi/chat/completions\" | Select-Object -Expand Content\nPython (OpenAI)\nYou can call the Function Calling API by using the OpenAI library. For more information, see\nCall Vertex AI models by using the OpenAI library\n.\nimport\nvertexai\nimport\nopenai\nfrom\ngoogle.auth\nimport\ndefault\n,\ntransport\n# TODO(developer): Update & uncomment below line\n# PROJECT_ID = \"your-project-id\"\nlocation\n=\n\"us-central1\"\nvertexai\n.\ninit\n(\nproject\n=\nPROJECT_ID\n,\nlocation\n=\nlocation\n)\n# Programmatically get an access token\ncredentials\n,\n_\n=\ndefault\n(\nscopes\n=\n[\n\"https://www.googleapis.com/auth/cloud-platform\"\n])\nauth_request\n=\ntransport\n.\nrequests\n.\nRequest\n()\ncredentials\n.\nrefresh\n(\nauth_request\n)\n# # OpenAI Client\nclient\n=\nopenai\n.\nOpenAI\n(\nbase_url\n=\nf\n\"https://\n{\nlocation\n}\n-aiplatform.googleapis.com/v1beta1/projects/\n{\nPROJECT_ID\n}\n/locations/\n{\nlocation\n}\n/endpoints/openapi\"\n,\napi_key\n=\ncredentials\n.\ntoken\n,\n)\ntools\n=\n[\n{\n\"type\"\n:\n\"function\"\n,\n\"function\"\n:\n{\n\"name\"\n:\n\"get_current_weather\"\n,\n\"description\"\n:\n\"Get the current weather in a given location\"\n,\n\"parameters\"\n:\n{\n\"type\"\n:\n\"object\"\n,\n\"properties\"\n:\n{\n\"location\"\n:\n{\n\"type\"\n:\n\"string\"\n,\n\"description\"\n:\n\"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n,\n},\n},\n\"required\"\n:\n[\n\"location\"\n],\n},\n},\n}\n]\nmessages\n=\n[]\nmessages\n.\nappend\n(\n{\n\"role\"\n:\n\"system\"\n,\n\"content\"\n:\n\"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\n,\n}\n)\nmessages\n.\nappend\n({\n\"role\"\n:\n\"user\"\n,\n\"content\"\n:\n\"What is the weather in Boston?\"\n})\nresponse\n=\nclient\n.\nchat\n.\ncompletions\n.\ncreate\n(\nmodel\n=\n\"google/gemini-2.0-flash-001\"\n,\nmessages\n=\nmessages\n,\ntools\n=\ntools\n,\n)\nprint\n(\n\"Function:\"\n,\nresponse\n.\nchoices\n[\n0\n]\n.\nmessage\n.\ntool_calls\n[\n0\n]\n.\nid\n)\nprint\n(\n\"Arguments:\"\n,\nresponse\n.\nchoices\n[\n0\n]\n.\nmessage\n.\ntool_calls\n[\n0\n]\n.\nfunction\n.\narguments\n)\n# Example response:\n# Function: get_current_weather\n# Arguments: {\"location\":\"Boston\"}\nSend a function declaration with\nFunctionCallingConfig\nThe following example demonstrates how to pass a\nFunctionCallingConfig\nto the model.\nThe\nfunctionCallingConfig\nensures that the model output is always a\nspecific function call. To configure:\nSet the function calling\nmode\nto\nANY\n.\nSpecify the function names that you want to use in\nallowed_function_names\n.\nIf\nallowed_function_names\nis empty, any of the provided functions\ncan be returned.\nREST\nPROJECT_ID\n=\nmyproject\nLOCATION\n=\nus-central1\nMODEL_ID\n=\ngemini-2.5-flash\ncurl\n-X\nPOST\n\\\n-H\n\"Authorization: Bearer\n$(\ngcloud\nauth\nprint-access-token\n)\n\"\n\\\n-H\n\"Content-Type: application/json\"\n\\\nhttps://\n${\nLOCATION\n}\n-aiplatform.googleapis.com/v1beta1/projects/\n${\nPROJECT_ID\n}\n/locations/\n${\nLOCATION\n}\n/publishers/google/models/\n${\nMODEL_ID\n}\n:generateContent\n\\\n-d\n'{\n\"contents\": [{\n\"role\": \"user\",\n\"parts\": [{\n\"text\": \"Do you have the White Pixel 8 Pro 128GB in stock in the US?\"\n}]\n}],\n\"tools\": [{\n\"functionDeclarations\": [\n{\n\"name\": \"get_product_sku\",\n\"description\": \"Get the available inventory for a Google products, e.g: Pixel phones, Pixel Watches, Google Home etc\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"product_name\": {\"type\": \"string\", \"description\": \"Product name\"}\n}\n}\n},\n{\n\"name\": \"get_store_location\",\n\"description\": \"Get the location of the closest store\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"location\": {\"type\": \"string\", \"description\": \"Location\"}\n},\n}\n}\n]\n}],\n\"toolConfig\": {\n\"functionCallingConfig\": {\n\"mode\":\"ANY\",\n\"allowedFunctionNames\": [\"get_product_sku\"]\n}\n},\n\"generationConfig\": {\n\"temperature\": 0.95,\n\"topP\": 1.0,\n\"maxOutputTokens\": 8192\n}\n}'\nGen AI SDK for Python\nfrom\ngoogle\nimport\ngenai\nfrom\ngoogle.genai.types\nimport\n(\nFunctionDeclaration\n,\nGenerateContentConfig\n,\nHttpOptions\n,\nTool\n,\n)\nclient\n=\ngenai\n.\nClient\n(\nhttp_options\n=\nHttpOptions\n(\napi_version\n=\n\"v1\"\n))\nmodel_id\n=\n\"gemini-2.5-flash\"\nget_album_sales\n=\nFunctionDeclaration\n(\nname\n=\n\"get_album_sales\"\n,\ndescription\n=\n\"Gets the number of albums sold\"\n,\n# Function parameters are specified in JSON schema format\nparameters\n=\n{\n\"type\"\n:\n\"OBJECT\"\n,\n\"properties\"\n:\n{\n\"albums\"\n:\n{\n\"type\"\n:\n\"ARRAY\"\n,\n\"description\"\n:\n\"List of albums\"\n,\n\"items\"\n:\n{\n\"description\"\n:\n\"Album and its sales\"\n,\n\"type\"\n:\n\"OBJECT\"\n,\n\"properties\"\n:\n{\n\"album_name\"\n:\n{\n\"type\"\n:\n\"STRING\"\n,\n\"description\"\n:\n\"Name of the music album\"\n,\n},\n\"copies_sold\"\n:\n{\n\"type\"\n:\n\"INTEGER\"\n,\n\"description\"\n:\n\"Number of copies sold\"\n,\n},\n},\n},\n},\n},\n},\n)\nsales_tool\n=\nTool\n(\nfunction_declarations\n=\n[\nget_album_sales\n],\n)\nresponse\n=\nclient\n.\nmodels\n.\ngenerate_content\n(\nmodel\n=\nmodel_id\n,\ncontents\n=\n'At Stellar Sounds, a music label, 2024 was a rollercoaster. \"Echoes of the Night,\" a debut synth-pop album, '\n'surprisingly sold 350,000 copies, while veteran rock band \"Crimson Tide\n\\'\ns\" latest, \"Reckless Hearts,\" '\n'lagged at 120,000. Their up-and-coming indie artist, \"Luna Bloom\n\\'\ns\" EP, \"Whispers of Dawn,\" '\n'secured 75,000 sales. The biggest disappointment was the highly-anticipated rap album \"Street Symphony\" '\n\"only reaching 100,000 units. Overall, Stellar Sounds moved over 645,000 units this year, revealing unexpected \"\n\"trends in music consumption.\"\n,\nconfig\n=\nGenerateContentConfig\n(\ntools\n=\n[\nsales_tool\n],\ntemperature\n=\n0\n,\n),\n)\nprint\n(\nresponse\n.\nfunction_calls\n)\n# Example response:\n# [FunctionCall(\n#     id=None,\n#     name=\"get_album_sales\",\n#     args={\n#         \"albums\": [\n#             {\"album_name\": \"Echoes of the Night\", \"copies_sold\": 350000},\n#             {\"copies_sold\": 120000, \"album_name\": \"Reckless Hearts\"},\n#             {\"copies_sold\": 75000, \"album_name\": \"Whispers of Dawn\"},\n#             {\"copies_sold\": 100000, \"album_name\": \"Street Symphony\"},\n#         ]\n#     },\n# )]\nNode.js\nconst\n{\nVertexAI\n,\nFunctionDeclarationSchemaType\n,\n}\n=\nrequire\n(\n'\n@google-cloud/vertexai\n'\n);\nconst\nfunctionDeclarations\n=\n[\n{\nfunction_declarations\n:\n[\n{\nname\n:\n'get_product_sku'\n,\ndescription\n:\n'Get the available inventory for a Google products, e.g: Pixel phones, Pixel Watches, Google Home etc'\n,\nparameters\n:\n{\ntype\n:\nFunctionDeclarationSchemaType\n.\nOBJECT\n,\nproperties\n:\n{\nproductName\n:\n{\ntype\n:\nFunctionDeclarationSchemaType\n.\nSTRING\n},\n},\n},\n},\n{\nname\n:\n'get_store_location'\n,\ndescription\n:\n'Get the location of the closest store'\n,\nparameters\n:\n{\ntype\n:\nFunctionDeclarationSchemaType\n.\nOBJECT\n,\nproperties\n:\n{\nlocation\n:\n{\ntype\n:\nFunctionDeclarationSchemaType\n.\nSTRING\n},\n},\n},\n},\n],\n},\n];\nconst\ntoolConfig\n=\n{\nfunction_calling_config\n:\n{\nmode\n:\n'\nANY\n'\n,\nallowed_function_names\n:\n[\n'get_product_sku'\n],\n},\n};\nconst\ngenerationConfig\n=\n{\ntemperature\n:\n0.95\n,\ntopP\n:\n1.0\n,\nmaxOutputTokens\n:\n8192\n,\n};\n/**\n* TODO(developer): Update these variables before running the sample.\n*/\nasync\nfunction\nfunctionCallingAdvanced\n(\nprojectId\n=\n'PROJECT_ID'\n,\nlocation\n=\n'us-central1'\n,\nmodel\n=\n'gemini-2.0-flash-001'\n)\n{\n// Initialize Vertex with your Cloud project and location\nconst\nvertexAI\n=\nnew\nVertexAI\n({\nproject\n:\nprojectId\n,\nlocation\n:\nlocation\n});\n// Instantiate the model\nconst\ngenerativeModel\n=\nvertexAI\n.\npreview\n.\ngetGenerativeModel\n({\nmodel\n:\nmodel\n,\n});\nconst\nrequest\n=\n{\ncontents\n:\n[\n{\nrole\n:\n'user'\n,\nparts\n:\n[\n{\ntext\n:\n'Do you have the White Pixel 8 Pro 128GB in stock in the US?'\n},\n],\n},\n],\ntools\n:\nfunctionDeclarations\n,\ntool_config\n:\ntoolConfig\n,\ngeneration_config\n:\ngenerationConfig\n,\n};\nconst\nresult\n=\nawait\ngenerativeModel\n.\ngenerateContent\n(\nrequest\n);\nconsole\n.\nlog\n(\nJSON\n.\nstringify\n(\nresult\n.\nresponse\n.\ncandidates\n[\n0\n].\ncontent\n));\n}\nGo\nimport\n(\n\"context\"\n\"encoding/json\"\n\"errors\"\n\"fmt\"\n\"io\"\n\"cloud.google.com/go/vertexai/genai\"\n)\n// functionCallsChat opens a chat session and sends 4 messages to the model:\n// - convert a first text question into a structured function call request\n// - convert the first structured function call response into natural language\n// - convert a second text question into a structured function call request\n// - convert the second structured function call response into natural language\nfunc\nfunctionCallsChat\n(\nw\nio\n.\nWriter\n,\nprojectID\n,\nlocation\n,\nmodelName\nstring\n)\nerror\n{\n// location := \"us-central1\"\n// modelName := \"gemini-2.0-flash-001\"\nctx\n:=\ncontext\n.\nBackground\n()\nclient\n,\nerr\n:=\ngenai\n.\nNewClient\n(\nctx\n,\nprojectID\n,\nlocation\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"unable to create client: %w\"\n,\nerr\n)\n}\ndefer\nclient\n.\nClose\n()\nmodel\n:=\nclient\n.\nGenerativeModel\n(\nmodelName\n)\n// Build an OpenAPI schema, in memory\nparamsProduct\n:=\n&\ngenai\n.\nSchema\n{\nType\n:\ngenai\n.\nTypeObject\n,\nProperties\n:\nmap\n[\nstring\n]\n*\ngenai\n.\nSchema\n{\n\"productName\"\n:\n{\nType\n:\ngenai\n.\nTypeString\n,\nDescription\n:\n\"Product name\"\n,\n},\n},\n}\nfundeclProductInfo\n:=\n&\ngenai\n.\nFunctionDeclaration\n{\nName\n:\n\"getProductSku\"\n,\nDescription\n:\n\"Get the SKU for a product\"\n,\nParameters\n:\nparamsProduct\n,\n}\nparamsStore\n:=\n&\ngenai\n.\nSchema\n{\nType\n:\ngenai\n.\nTypeObject\n,\nProperties\n:\nmap\n[\nstring\n]\n*\ngenai\n.\nSchema\n{\n\"location\"\n:\n{\nType\n:\ngenai\n.\nTypeString\n,\nDescription\n:\n\"Location\"\n,\n},\n},\n}\nfundeclStoreLocation\n:=\n&\ngenai\n.\nFunctionDeclaration\n{\nName\n:\n\"getStoreLocation\"\n,\nDescription\n:\n\"Get the location of the closest store\"\n,\nParameters\n:\nparamsStore\n,\n}\nmodel\n.\nTools\n=\n[]\n*\ngenai\n.\nTool\n{\n{\nFunctionDeclarations\n:\n[]\n*\ngenai\n.\nFunctionDeclaration\n{\nfundeclProductInfo\n,\nfundeclStoreLocation\n,\n}},\n}\nmodel\n.\nSetTemperature\n(\n0.0\n)\nchat\n:=\nmodel\n.\nStartChat\n()\n// Send a prompt for the first conversation turn that should invoke the getProductSku function\nprompt\n:=\n\"Do you have the Pixel 8 Pro in stock?\"\nfmt\n.\nFprintf\n(\nw\n,\n\"Question: %s\\n\"\n,\nprompt\n)\nresp\n,\nerr\n:=\nchat\n.\nSendMessage\n(\nctx\n,\ngenai\n.\nText\n(\nprompt\n))\nif\nerr\n!=\nnil\n{\nreturn\nerr\n}\nif\nlen\n(\nresp\n.\nCandidates\n)\n==\n0\n||\nlen\n(\nresp\n.\nCandidates\n[\n0\n].\nContent\n.\nParts\n)\n==\n0\n{\nreturn\nerrors\n.\nNew\n(\n\"empty response from model\"\n)\n}\n// The model has returned a function call to the declared function `getProductSku`\n// with a value for the argument `productName`.\njsondata\n,\nerr\n:=\njson\n.\nMarshalIndent\n(\nresp\n.\nCandidates\n[\n0\n].\nContent\n.\nParts\n[\n0\n],\n\"\\t\"\n,\n\"  \"\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"json.MarshalIndent: %w\"\n,\nerr\n)\n}\nfmt\n.\nFprintf\n(\nw\n,\n\"function call generated by the model:\\n\\t%s\\n\"\n,\nstring\n(\njsondata\n))\n// Create a function call response, to simulate the result of a call to a\n// real service\nfunresp\n:=\n&\ngenai\n.\nFunctionResponse\n{\nName\n:\n\"getProductSku\"\n,\nResponse\n:\nmap\n[\nstring\n]\nany\n{\n\"sku\"\n:\n\"GA04834-US\"\n,\n\"in_stock\"\n:\n\"yes\"\n,\n},\n}\njsondata\n,\nerr\n=\njson\n.\nMarshalIndent\n(\nfunresp\n,\n\"\\t\"\n,\n\"  \"\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"json.MarshalIndent: %w\"\n,\nerr\n)\n}\nfmt\n.\nFprintf\n(\nw\n,\n\"function call response sent to the model:\\n\\t%s\\n\\n\"\n,\nstring\n(\njsondata\n))\n// And provide the function call response to the model\nresp\n,\nerr\n=\nchat\n.\nSendMessage\n(\nctx\n,\nfunresp\n)\nif\nerr\n!=\nnil\n{\nreturn\nerr\n}\nif\nlen\n(\nresp\n.\nCandidates\n)\n==\n0\n||\nlen\n(\nresp\n.\nCandidates\n[\n0\n].\nContent\n.\nParts\n)\n==\n0\n{\nreturn\nerrors\n.\nNew\n(\n\"empty response from model\"\n)\n}\n// The model has taken the function call response as input, and has\n// reformulated the response to the user.\njsondata\n,\nerr\n=\njson\n.\nMarshalIndent\n(\nresp\n.\nCandidates\n[\n0\n].\nContent\n.\nParts\n[\n0\n],\n\"\\t\"\n,\n\"  \"\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"json.MarshalIndent: %w\"\n,\nerr\n)\n}\nfmt\n.\nFprintf\n(\nw\n,\n\"Answer generated by the model:\\n\\t%s\\n\\n\"\n,\nstring\n(\njsondata\n))\n// Send a prompt for the second conversation turn that should invoke the getStoreLocation function\nprompt2\n:=\n\"Is there a store in Mountain View, CA that I can visit to try it out?\"\nfmt\n.\nFprintf\n(\nw\n,\n\"Question: %s\\n\"\n,\nprompt\n)\nresp\n,\nerr\n=\nchat\n.\nSendMessage\n(\nctx\n,\ngenai\n.\nText\n(\nprompt2\n))\nif\nerr\n!=\nnil\n{\nreturn\nerr\n}\nif\nlen\n(\nresp\n.\nCandidates\n)\n==\n0\n||\nlen\n(\nresp\n.\nCandidates\n[\n0\n].\nContent\n.\nParts\n)\n==\n0\n{\nreturn\nerrors\n.\nNew\n(\n\"empty response from model\"\n)\n}\n// The model has returned a function call to the declared function `getStoreLocation`\n// with a value for the argument `store`.\njsondata\n,\nerr\n=\njson\n.\nMarshalIndent\n(\nresp\n.\nCandidates\n[\n0\n].\nContent\n.\nParts\n[\n0\n],\n\"\\t\"\n,\n\"  \"\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"json.MarshalIndent: %w\"\n,\nerr\n)\n}\nfmt\n.\nFprintf\n(\nw\n,\n\"function call generated by the model:\\n\\t%s\\n\"\n,\nstring\n(\njsondata\n))\n// Create a function call response, to simulate the result of a call to a\n// real service\nfunresp\n=\n&\ngenai\n.\nFunctionResponse\n{\nName\n:\n\"getStoreLocation\"\n,\nResponse\n:\nmap\n[\nstring\n]\nany\n{\n\"store\"\n:\n\"2000 N Shoreline Blvd, Mountain View, CA 94043, US\"\n,\n},\n}\njsondata\n,\nerr\n=\njson\n.\nMarshalIndent\n(\nfunresp\n,\n\"\\t\"\n,\n\"  \"\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"json.MarshalIndent: %w\"\n,\nerr\n)\n}\nfmt\n.\nFprintf\n(\nw\n,\n\"function call response sent to the model:\\n\\t%s\\n\\n\"\n,\nstring\n(\njsondata\n))\n// And provide the function call response to the model\nresp\n,\nerr\n=\nchat\n.\nSendMessage\n(\nctx\n,\nfunresp\n)\nif\nerr\n!=\nnil\n{\nreturn\nerr\n}\nif\nlen\n(\nresp\n.\nCandidates\n)\n==\n0\n||\nlen\n(\nresp\n.\nCandidates\n[\n0\n].\nContent\n.\nParts\n)\n==\n0\n{\nreturn\nerrors\n.\nNew\n(\n\"empty response from model\"\n)\n}\n// The model has taken the function call response as input, and has\n// reformulated the response to the user.\njsondata\n,\nerr\n=\njson\n.\nMarshalIndent\n(\nresp\n.\nCandidates\n[\n0\n].\nContent\n.\nParts\n[\n0\n],\n\"\\t\"\n,\n\"  \"\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"json.MarshalIndent: %w\"\n,\nerr\n)\n}\nfmt\n.\nFprintf\n(\nw\n,\n\"Answer generated by the model:\\n\\t%s\\n\\n\"\n,\nstring\n(\njsondata\n))\nreturn\nnil\n}\nREST (OpenAI)\nYou can call the Function Calling API by using the OpenAI library. For more information, see\nCall Vertex AI models by using the OpenAI library\n.\nBefore using any of the request data,\nmake the following replacements:\nPROJECT_ID\n: .\nMODEL_ID\n: The ID of the model that's being processed.\nHTTP method and URL:\nPOST https://aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/global/endpoints/openapi/chat/completions\nRequest JSON body:\n{\n\"model\": \"google/\nMODEL_ID\n\",\n\"messages\": [\n{\n\"role\": \"user\",\n\"content\": \"What is the weather in Boston?\"\n}\n],\n\"tools\": [\n{\n\"type\": \"function\",\n\"function\": {\n\"name\": \"get_current_weather\",\n\"description\": \"Get the current weather in a given location\",\n\"parameters\": {\n\"type\": \"OBJECT\",\n\"properties\": {\n\"location\": {\n\"type\": \"string\",\n\"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n}\n},\n\"required\": [\"location\"]\n}\n}\n}\n],\n\"tool_choice\": \"auto\"\n}\nTo send your request, choose one of these options:\ncurl\nSave the request body in a file named\nrequest.json\n,\nand execute the following command:\ncurl -X POST \\\n-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n-H \"Content-Type: application/json; charset=utf-8\" \\\n-d @request.json \\\n\"https://aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/global/endpoints/openapi/chat/completions\"\nPowerShell\nSave the request body in a file named\nrequest.json\n,\nand execute the following command:\n$cred = gcloud auth print-access-token\n$headers = @{ \"Authorization\" = \"Bearer $cred\" }\nInvoke-WebRequest `\n-Method POST `\n-Headers $headers `\n-ContentType: \"application/json; charset=utf-8\" `\n-InFile request.json `\n-Uri \"https://aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/global/endpoints/openapi/chat/completions\" | Select-Object -Expand Content\nPython (OpenAI)\nYou can call the Function Calling API by using the OpenAI library. For more information, see\nCall Vertex AI models by using the OpenAI library\n.\nimport\nvertexai\nimport\nopenai\nfrom\ngoogle.auth\nimport\ndefault\n,\ntransport\n# TODO(developer): Update & uncomment below line\n# PROJECT_ID = \"your-project-id\"\nlocation\n=\n\"us-central1\"\nvertexai\n.\ninit\n(\nproject\n=\nPROJECT_ID\n,\nlocation\n=\nlocation\n)\n# Programmatically get an access token\ncredentials\n,\n_\n=\ndefault\n(\nscopes\n=\n[\n\"https://www.googleapis.com/auth/cloud-platform\"\n])\nauth_request\n=\ntransport\n.\nrequests\n.\nRequest\n()\ncredentials\n.\nrefresh\n(\nauth_request\n)\n# OpenAI Client\nclient\n=\nopenai\n.\nOpenAI\n(\nbase_url\n=\nf\n\"https://\n{\nlocation\n}\n-aiplatform.googleapis.com/v1beta1/projects/\n{\nPROJECT_ID\n}\n/locations/\n{\nlocation\n}\n/endpoints/openapi\"\n,\napi_key\n=\ncredentials\n.\ntoken\n,\n)\ntools\n=\n[\n{\n\"type\"\n:\n\"function\"\n,\n\"function\"\n:\n{\n\"name\"\n:\n\"get_current_weather\"\n,\n\"description\"\n:\n\"Get the current weather in a given location\"\n,\n\"parameters\"\n:\n{\n\"type\"\n:\n\"object\"\n,\n\"properties\"\n:\n{\n\"location\"\n:\n{\n\"type\"\n:\n\"string\"\n,\n\"description\"\n:\n\"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n,\n},\n},\n\"required\"\n:\n[\n\"location\"\n],\n},\n},\n}\n]\nmessages\n=\n[]\nmessages\n.\nappend\n(\n{\n\"role\"\n:\n\"system\"\n,\n\"content\"\n:\n\"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"\n,\n}\n)\nmessages\n.\nappend\n({\n\"role\"\n:\n\"user\"\n,\n\"content\"\n:\n\"What is the weather in Boston, MA?\"\n})\nresponse\n=\nclient\n.\nchat\n.\ncompletions\n.\ncreate\n(\nmodel\n=\n\"google/gemini-2.0-flash-001\"\n,\nmessages\n=\nmessages\n,\ntools\n=\ntools\n,\ntool_choice\n=\n\"auto\"\n,\n)\nprint\n(\n\"Function:\"\n,\nresponse\n.\nchoices\n[\n0\n]\n.\nmessage\n.\ntool_calls\n[\n0\n]\n.\nid\n)\nprint\n(\n\"Arguments:\"\n,\nresponse\n.\nchoices\n[\n0\n]\n.\nmessage\n.\ntool_calls\n[\n0\n]\n.\nfunction\n.\narguments\n)\n# Example response:\n# Function: get_current_weather\n# Arguments: {\"location\":\"Boston\"}\nWhat's next\nFor detailed documentation, see the following:\nFunction calling\nSend feedback\nExcept as otherwise noted, the content of this page is licensed under the\nCreative Commons Attribution 4.0 License\n, and code samples are licensed under the\nApache 2.0 License\n. For details, see the\nGoogle Developers Site Policies\n. Java is a registered trademark of Oracle and/or its affiliates.\nLast updated 2025-11-07 UTC.",
  "metadata": {
    "title": "Function calling reference  |  Generative AI on Vertex AI  |  Google Cloud Documentation",
    "extracted_at": "2025-11-11 14:27:18"
  }
}