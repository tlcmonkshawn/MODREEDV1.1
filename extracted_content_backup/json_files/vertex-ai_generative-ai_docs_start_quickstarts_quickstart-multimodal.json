{
  "url": "https://docs.cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal",
  "title": "Gemini API in Vertex AI quickstart  |  Generative AI on Vertex AI  |  Google Cloud Documentation",
  "text_content": "Home\nTechnology areas\nGenerative AI on Vertex AI\nDocumentation\nSend feedback\nGemini API in Vertex AI quickstart\nStay organized with collections\nSave and categorize content based on your preferences.\nThis quickstart shows you how to install the Google Gen AI SDK for your\nlanguage of choice and then make your first API request. The samples vary\nslightly based on whether you authenticate to Vertex AI using an\nAPI key\nor\napplication default credentials (ADC)\n.\nChoose your authentication method:\nADC\nAPI key\nBefore you begin\nIf you haven't configured ADC yet, follow these instructions:\nConfigure your project\nSelect a project, enable billing, enable the Vertex AI API, and install gcloud CLI:\nSign in\nto your Google Account.\nIf you don't already have one,\nsign up for a new account\n.\nIn the Google Cloud console, on the project selector page,\nselect or create a Google Cloud project.\nRoles required to select or create a project\nSelect a project\n: Selecting a project doesn't require a specific\nIAM role—you can select any project that you've been\ngranted a role on.\nCreate a project\n: To create a project, you need the Project Creator\n(\nroles/resourcemanager.projectCreator\n), which contains the\nresourcemanager.projects.create\npermission.\nLearn how to grant\nroles\n.\nGo to project selector\nVerify that billing is enabled for your Google Cloud project\n.\nEnable the Vertex AI API.\nRoles required to enable APIs\nTo enable APIs, you need the Service Usage Admin IAM\nrole (\nroles/serviceusage.serviceUsageAdmin\n), which\ncontains the\nserviceusage.services.enable\npermission.\nLearn how to grant\nroles\n.\nEnable the API\nInstall\nthe Google Cloud CLI.\nIf you're using an external identity provider (IdP), you must first\nsign in to the gcloud CLI with your federated identity\n.\nTo\ninitialize\nthe gcloud CLI, run the following command:\ngcloud\ninit\nIn the Google Cloud console, on the project selector page,\nselect or create a Google Cloud project.\nRoles required to select or create a project\nSelect a project\n: Selecting a project doesn't require a specific\nIAM role—you can select any project that you've been\ngranted a role on.\nCreate a project\n: To create a project, you need the Project Creator\n(\nroles/resourcemanager.projectCreator\n), which contains the\nresourcemanager.projects.create\npermission.\nLearn how to grant\nroles\n.\nGo to project selector\nVerify that billing is enabled for your Google Cloud project\n.\nEnable the Vertex AI API.\nRoles required to enable APIs\nTo enable APIs, you need the Service Usage Admin IAM\nrole (\nroles/serviceusage.serviceUsageAdmin\n), which\ncontains the\nserviceusage.services.enable\npermission.\nLearn how to grant\nroles\n.\nEnable the API\nInstall\nthe Google Cloud CLI.\nIf you're using an external identity provider (IdP), you must first\nsign in to the gcloud CLI with your federated identity\n.\nTo\ninitialize\nthe gcloud CLI, run the following command:\ngcloud\ninit\nCreate local authentication credentials\nCreate local authentication credentials for your user account:\ngcloud\nauth\napplication-default\nlogin\nIf an authentication error is returned, and you are using an external identity provider\n(IdP), confirm that you have\nsigned in to the gcloud CLI with your federated identity\n.\nRequired roles\nTo get the permissions that\nyou need to use the Gemini API in Vertex AI,\nask your administrator to grant you the\nVertex AI User\n(\nroles/aiplatform.user\n)\nIAM role on your project.\nFor more information about granting roles, see\nManage access to projects, folders, and organizations\n.\nYou might also be able to get\nthe required permissions through\ncustom\nroles\nor other\npredefined\nroles\n.\nInstall the SDK and set up your environment\nOn your local machine, click one of the following tabs to install the SDK for\nyour programming language.\nPython Gen AI SDK\nInstall and update the Gen AI SDK for Python by running this command.\npip\ninstall\n--upgrade\ngoogle-genai\nSet environment variables:\n# Replace the `GOOGLE_CLOUD_PROJECT_ID` and `GOOGLE_CLOUD_LOCATION` values\n# with appropriate values for your project.\nexport\nGOOGLE_CLOUD_PROJECT\n=\nGOOGLE_CLOUD_PROJECT_ID\nexport\nGOOGLE_CLOUD_LOCATION\n=\nglobal\nexport\nGOOGLE_GENAI_USE_VERTEXAI\n=\nTrue\nGo Gen AI SDK\nInstall and update the Gen AI SDK for Go by running this command.\ngo\nget\ngoogle.golang.org/genai\nSet environment variables:\n# Replace the `GOOGLE_CLOUD_PROJECT_ID` and `GOOGLE_CLOUD_LOCATION` values\n# with appropriate values for your project.\nexport\nGOOGLE_CLOUD_PROJECT\n=\nGOOGLE_CLOUD_PROJECT_ID\nexport\nGOOGLE_CLOUD_LOCATION\n=\nglobal\nexport\nGOOGLE_GENAI_USE_VERTEXAI\n=\nTrue\nNode.js Gen AI SDK\nInstall and update the Gen AI SDK for Node.js by running this command.\nnpm\ninstall\n@google/genai\nSet environment variables:\n# Replace the `GOOGLE_CLOUD_PROJECT_ID` and `GOOGLE_CLOUD_LOCATION` values\n# with appropriate values for your project.\nexport\nGOOGLE_CLOUD_PROJECT\n=\nGOOGLE_CLOUD_PROJECT_ID\nexport\nGOOGLE_CLOUD_LOCATION\n=\nglobal\nexport\nGOOGLE_GENAI_USE_VERTEXAI\n=\nTrue\nJava Gen AI SDK\nInstall and update the Gen AI SDK for Java by running this command.\nMaven\nAdd the following to your\npom.xml\n:\n<dependencies>\n<dependency>\n<groupId>com.google.genai</groupId>\n<artifactId>google-genai</artifactId>\n<version>0.7.0</version>\n</dependency>\n</dependencies>\nSet environment variables:\n# Replace the `GOOGLE_CLOUD_PROJECT_ID` and `GOOGLE_CLOUD_LOCATION` values\n# with appropriate values for your project.\nexport\nGOOGLE_CLOUD_PROJECT\n=\nGOOGLE_CLOUD_PROJECT_ID\nexport\nGOOGLE_CLOUD_LOCATION\n=\nglobal\nexport\nGOOGLE_GENAI_USE_VERTEXAI\n=\nTrue\nREST\nSet environment variables:\nGOOGLE_CLOUD_PROJECT\n=\nGOOGLE_CLOUD_PROJECT_ID\nGOOGLE_CLOUD_LOCATION\n=\nglobal\nAPI_ENDPOINT\n=\nYOUR_API_ENDPOINT\nMODEL_ID\n=\n\"gemini-2.5-flash\"\nGENERATE_CONTENT_API\n=\n\"generateContent\"\nMake your first request\nUse the\ngenerateContent\nmethod to send a request to the Gemini API in Vertex AI:\nPython\nfrom\ngoogle\nimport\ngenai\nfrom\ngoogle.genai.types\nimport\nHttpOptions\nclient\n=\ngenai\n.\nClient\n(\nhttp_options\n=\nHttpOptions\n(\napi_version\n=\n\"v1\"\n))\nresponse\n=\nclient\n.\nmodels\n.\ngenerate_content\n(\nmodel\n=\n\"gemini-2.5-flash\"\n,\ncontents\n=\n\"How does AI work?\"\n,\n)\nprint\n(\nresponse\n.\ntext\n)\n# Example response:\n# Okay, let's break down how AI works. It's a broad field, so I'll focus on the ...\n#\n# Here's a simplified overview:\n# ...\nGo\nimport\n(\n\"context\"\n\"fmt\"\n\"io\"\n\"google.golang.org/genai\"\n)\n//\ngenerateWithText\nshows\nhow\nto\ngenerate\ntext\nusing\na\ntext\nprompt\n.\nfunc\ngenerateWithText\n(\nw\nio\n.\nWriter\n)\nerror\n{\nctx\n:=\ncontext\n.\nBackground\n()\nclient\n,\nerr\n:=\ngenai\n.\nNewClient\n(\nctx\n,\n&\ngenai\n.\nClientConfig\n{\nHTTPOptions\n:\ngenai\n.\nHTTPOptions\n{\nAPIVersion\n:\n\"v1\"\n},\n})\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to create genai client: %w\"\n,\nerr\n)\n}\nresp\n,\nerr\n:=\nclient\n.\nModels\n.\nGenerateContent\n(\nctx\n,\n\"gemini-2.5-flash\"\n,\ngenai\n.\nText\n(\n\"How does AI work?\"\n),\nnil\n,\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to generate content: %w\"\n,\nerr\n)\n}\nrespText\n:=\nresp\n.\nText\n()\nfmt\n.\nFprintln\n(\nw\n,\nrespText\n)\n//\nExample\nresponse\n:\n//\nThat\n's a great question! Understanding how AI works can feel like ...\n//\n...\n//\n**\n1.\nThe\nFoundation\n:\nData\nand\nAlgorithms\n**\n//\n...\nreturn\nnil\n}\nNode.js\nconst\n{\nGoogleGenAI\n}\n=\nrequire\n(\n'@google/genai'\n);\nconst\nGOOGLE_CLOUD_PROJECT\n=\nprocess\n.\nenv\n.\nGOOGLE_CLOUD_PROJECT\n;\nconst\nGOOGLE_CLOUD_LOCATION\n=\nprocess\n.\nenv\n.\nGOOGLE_CLOUD_LOCATION\n||\n'global'\n;\nasync\nfunction\ngenerateContent\n(\nprojectId\n=\nGOOGLE_CLOUD_PROJECT\n,\nlocation\n=\nGOOGLE_CLOUD_LOCATION\n)\n{\nconst\nclient\n=\nnew\nGoogleGenAI\n({\nvertexai\n:\ntrue\n,\nproject\n:\nprojectId\n,\nlocation\n:\nlocation\n,\n});\nconst\nresponse\n=\nawait\nclient\n.\nmodels\n.\ngenerateContent\n({\nmodel\n:\n'gemini-2.5-flash'\n,\ncontents\n:\n'How does AI work?'\n,\n});\nconsole\n.\nlog\n(\nresponse\n.\ntext\n);\nreturn\nresponse\n.\ntext\n;\n}\nJava\nimport\ncom.google.genai.Client\n;\nimport\ncom.google.genai.types.GenerateContentResponse\n;\nimport\ncom.google.genai.types.HttpOptions\n;\npublic\nclass\nTextGenerationWithText\n{\npublic\nstatic\nvoid\nmain\n(\nString\n[]\nargs\n)\n{\n//\nTODO\n(\ndeveloper\n):\nReplace\nthese\nvariables\nbefore\nrunning\nthe\nsample\n.\nString\nmodelId\n=\n\"gemini-2.5-flash\"\n;\ngenerateContent\n(\nmodelId\n);\n}\n//\nGenerates\ntext\nwith\ntext\ninput\npublic\nstatic\nString\ngenerateContent\n(\nString\nmodelId\n)\n{\n//\nInitialize\nclient\nthat\nwill\nbe\nused\nto\nsend\nrequests\n.\nThis\nclient\nonly\nneeds\nto\nbe\ncreated\n//\nonce\n,\nand\ncan\nbe\nreused\nfor\nmultiple\nrequests\n.\ntry\n(\nClient\nclient\n=\nClient\n.\nbuilder\n()\n.\nlocation\n(\n\"global\"\n)\n.\nvertexAI\n(\ntrue\n)\n.\nhttpOptions\n(\nHttpOptions\n.\nbuilder\n()\n.\napiVersion\n(\n\"v1\"\n)\n.\nbuild\n())\n.\nbuild\n())\n{\nGenerateContentResponse\nresponse\n=\nclient\n.\nmodels\n.\ngenerateContent\n(\nmodelId\n,\n\"How does AI work?\"\n,\nnull\n);\nSystem\n.\nout\n.\nprint\n(\nresponse\n.\ntext\n());\n//\nExample\nresponse\n:\n//\nOkay\n,\nlet\n's break down how AI works. It'\ns\na\nbroad\nfield\n,\nso\nI\n'll focus on the ...\n//\n//\nHere\n's a simplified overview:\n//\n...\nreturn\nresponse\n.\ntext\n();\n}\n}\n}\nREST\nTo send this prompt request, run the curl command from the command line or\ninclude the REST call in your application.\ncurl\n-X\nPOST\n-H\n\"Content-Type: application/json\"\n-H\n\"Authorization: Bearer\n$(\ngcloud\nauth\nprint-access-token\n)\n\"\n\"https://\n${\nAPI_ENDPOINT\n}\n/v1/projects/\n${\nGOOGLE_CLOUD_PROJECT\n}\n/locations/\n${\nGOOGLE_CLOUD_LOCATION\n}\n/publishers/google/models/\n${\nMODEL_ID\n}\n:\n${\nGENERATE_CONTENT_API\n}\n\"\n-d\n$'{\n\"contents\": {\n\"role\": \"user\",\n\"parts\": {\n\"text\": \"Explain how AI works in a few words\"\n}\n}\n}'\nThe model returns a response. Note that the response is generated in sections\nwith each section separately evaluated for safety.\nGenerate images\nGemini can generate and process images conversationally. You can prompt\nGemini with text, images, or a combination of both to achieve various\nimage-related tasks, such as image generation and editing. The following code\ndemonstrates how to generate an image based on a descriptive prompt:\nYou must include\nresponseModalities: [\"TEXT\", \"IMAGE\"]\nin your\nconfiguration. Image-only output is not supported with these models.\nPython\nfrom\ngoogle\nimport\ngenai\nfrom\ngoogle.genai.types\nimport\nGenerateContentConfig\n,\nModality\nfrom\nPIL\nimport\nImage\nfrom\nio\nimport\nBytesIO\nclient\n=\ngenai\n.\nClient\n()\nresponse\n=\nclient\n.\nmodels\n.\ngenerate_content\n(\nmodel\n=\n\"gemini-2.5-flash-image\"\n,\ncontents\n=\n(\n\"Generate an image of the Eiffel tower with fireworks in the background.\"\n),\nconfig\n=\nGenerateContentConfig\n(\nresponse_modalities\n=\n[\nModality\n.\nTEXT\n,\nModality\n.\nIMAGE\n],\ncandidate_count\n=\n1\n,\nsafety_settings\n=\n[\n{\n\"method\"\n:\n\"PROBABILITY\"\n},\n{\n\"category\"\n:\n\"HARM_CATEGORY_DANGEROUS_CONTENT\"\n},\n{\n\"threshold\"\n:\n\"BLOCK_MEDIUM_AND_ABOVE\"\n},\n],\n),\n)\nfor\npart\nin\nresponse\n.\ncandidates\n[\n0\n]\n.\ncontent\n.\nparts\n:\nif\npart\n.\ntext\n:\nprint\n(\npart\n.\ntext\n)\nelif\npart\n.\ninline_data\n:\nimage\n=\nImage\n.\nopen\n(\nBytesIO\n((\npart\n.\ninline_data\n.\ndata\n)))\nimage\n.\nsave\n(\n\"output_folder/example-image-eiffel-tower.png\"\n)\n# Example response:\n#   I will generate an image of the Eiffel Tower at night, with a vibrant display of\n#   colorful fireworks exploding in the dark sky behind it. The tower will be\n#   illuminated, standing tall as the focal point of the scene, with the bursts of\n#   light from the fireworks creating a festive atmosphere.\nNode.js\nconst\nfs\n=\nrequire\n(\n'fs'\n);\nconst\n{\nGoogleGenAI\n,\nModality\n}\n=\nrequire\n(\n'@google/genai'\n);\nconst\nGOOGLE_CLOUD_PROJECT\n=\nprocess\n.\nenv\n.\nGOOGLE_CLOUD_PROJECT\n;\nconst\nGOOGLE_CLOUD_LOCATION\n=\nprocess\n.\nenv\n.\nGOOGLE_CLOUD_LOCATION\n||\n'us-central1'\n;\nasync\nfunction\ngenerateImage\n(\nprojectId\n=\nGOOGLE_CLOUD_PROJECT\n,\nlocation\n=\nGOOGLE_CLOUD_LOCATION\n)\n{\nconst\nclient\n=\nnew\nGoogleGenAI\n({\nvertexai\n:\ntrue\n,\nproject\n:\nprojectId\n,\nlocation\n:\nlocation\n,\n});\nconst\nresponse\n=\nawait\nclient\n.\nmodels\n.\ngenerateContentStream\n({\nmodel\n:\n'gemini-2.5-flash-image'\n,\ncontents\n:\n'Generate an image of the Eiffel tower with fireworks in the background.'\n,\nconfig\n:\n{\nresponseModalities\n:\n[\nModality\n.\nTEXT\n,\nModality\n.\nIMAGE\n],\n},\n});\nconst\ngeneratedFileNames\n=\n[];\nlet\nimageIndex\n=\n0\n;\nfor\nawait\n(\nconst\nchunk\nof\nresponse\n)\n{\nconst\ntext\n=\nchunk\n.\ntext\n;\nconst\ndata\n=\nchunk\n.\ndata\n;\nif\n(\ntext\n)\n{\nconsole\n.\ndebug\n(\ntext\n);\n}\nelse\nif\n(\ndata\n)\n{\nconst\noutputDir\n=\n'output-folder'\n;\nif\n(\n!\nfs\n.\nexistsSync\n(\noutputDir\n))\n{\nfs\n.\nmkdirSync\n(\noutputDir\n,\n{\nrecursive\n:\ntrue\n});\n}\nconst\nfileName\n=\n`\n$\n{\noutputDir\n}\n/\ngenerate_content_streaming_image_\n$\n{\nimageIndex\n++\n}\n.\npng\n`\n;\nconsole\n.\ndebug\n(\n`\nWriting\nresponse\nimage\nto\nfile\n:\n$\n{\nfileName\n}\n.\n`\n);\ntry\n{\nfs\n.\nwriteFileSync\n(\nfileName\n,\ndata\n);\ngeneratedFileNames\n.\npush\n(\nfileName\n);\n}\ncatch\n(\nerror\n)\n{\nconsole\n.\nerror\n(\n`\nFailed\nto\nwrite\nimage\nfile\n$\n{\nfileName\n}:\n`\n,\nerror\n);\n}\n}\n}\n//\nExample\nresponse\n:\n//\nI\nwill\ngenerate\nan\nimage\nof\nthe\nEiffel\nTower\nat\nnight\n,\nwith\na\nvibrant\ndisplay\nof\n//\ncolorful\nfireworks\nexploding\nin\nthe\ndark\nsky\nbehind\nit\n.\nThe\ntower\nwill\nbe\n//\nilluminated\n,\nstanding\ntall\nas\nthe\nfocal\npoint\nof\nthe\nscene\n,\nwith\nthe\nbursts\nof\n//\nlight\nfrom\nthe\nfireworks\ncreating\na\nfestive\natmosphere\n.\nreturn\ngeneratedFileNames\n;\n}\nJava\nimport\ncom.google.genai.Client\n;\nimport\ncom.google.genai.types.Blob\n;\nimport\ncom.google.genai.types.Candidate\n;\nimport\ncom.google.genai.types.Content\n;\nimport\ncom.google.genai.types.GenerateContentConfig\n;\nimport\ncom.google.genai.types.GenerateContentResponse\n;\nimport\ncom.google.genai.types.Part\n;\nimport\ncom.google.genai.types.SafetySetting\n;\nimport\njava.awt.image.BufferedImage\n;\nimport\njava.io.ByteArrayInputStream\n;\nimport\njava.io.File\n;\nimport\njava.io.IOException\n;\nimport\njava.util.ArrayList\n;\nimport\njava.util.List\n;\nimport\njavax.imageio.ImageIO\n;\npublic\nclass\nImageGenMmFlashWithText\n{\npublic\nstatic\nvoid\nmain\n(\nString\n[]\nargs\n)\nthrows\nIOException\n{\n//\nTODO\n(\ndeveloper\n):\nReplace\nthese\nvariables\nbefore\nrunning\nthe\nsample\n.\nString\nmodelId\n=\n\"gemini-2.5-flash-image\"\n;\nString\noutputFile\n=\n\"resources/output/example-image-eiffel-tower.png\"\n;\ngenerateContent\n(\nmodelId\n,\noutputFile\n);\n}\n//\nGenerates\nan\nimage\nwith\ntext\ninput\npublic\nstatic\nvoid\ngenerateContent\n(\nString\nmodelId\n,\nString\noutputFile\n)\nthrows\nIOException\n{\n//\nClient\nInitialization\n.\nOnce\ncreated\n,\nit\ncan\nbe\nreused\nfor\nmultiple\nrequests\n.\ntry\n(\nClient\nclient\n=\nClient\n.\nbuilder\n()\n.\nlocation\n(\n\"global\"\n)\n.\nvertexAI\n(\ntrue\n)\n.\nbuild\n())\n{\nGenerateContentConfig\ncontentConfig\n=\nGenerateContentConfig\n.\nbuilder\n()\n.\nresponseModalities\n(\n\"TEXT\"\n,\n\"IMAGE\"\n)\n.\ncandidateCount\n(\n1\n)\n.\nsafetySettings\n(\nSafetySetting\n.\nbuilder\n()\n.\nmethod\n(\n\"PROBABILITY\"\n)\n.\ncategory\n(\n\"HARM_CATEGORY_DANGEROUS_CONTENT\"\n)\n.\nthreshold\n(\n\"BLOCK_MEDIUM_AND_ABOVE\"\n)\n.\nbuild\n())\n.\nbuild\n();\nGenerateContentResponse\nresponse\n=\nclient\n.\nmodels\n.\ngenerateContent\n(\nmodelId\n,\n\"Generate an image of the Eiffel tower with fireworks in the background.\"\n,\ncontentConfig\n);\n//\nGet\nparts\nof\nthe\nresponse\nList<Part>\nparts\n=\nresponse\n.\ncandidates\n()\n.\nflatMap\n(\ncandidates\n-\n>\ncandidates\n.\nstream\n()\n.\nfindFirst\n())\n.\nflatMap\n(\nCandidate\n::\ncontent\n)\n.\nflatMap\n(\nContent\n::\nparts\n)\n.\norElse\n(\nnew\nArrayList\n<>\n());\n//\nFor\neach\npart\nprint\ntext\nif\npresent\n,\notherwise\nread\nimage\ndata\nif\npresent\nand\n//\nwrite\nit\nto\nthe\noutput\nfile\nfor\n(\nPart\npart\n:\nparts\n)\n{\nif\n(\npart\n.\ntext\n()\n.\nisPresent\n())\n{\nSystem\n.\nout\n.\nprintln\n(\npart\n.\ntext\n()\n.\nget\n());\n}\nelse\nif\n(\npart\n.\ninlineData\n()\n.\nflatMap\n(\nBlob\n::\ndata\n)\n.\nisPresent\n())\n{\nBufferedImage\nimage\n=\nImageIO\n.\nread\n(\nnew\nByteArrayInputStream\n(\npart\n.\ninlineData\n()\n.\nflatMap\n(\nBlob\n::\ndata\n)\n.\nget\n()));\nImageIO\n.\nwrite\n(\nimage\n,\n\"png\"\n,\nnew\nFile\n(\noutputFile\n));\n}\n}\nSystem\n.\nout\n.\nprintln\n(\n\"Content written to: \"\n+\noutputFile\n);\n//\nExample\nresponse\n:\n//\nHere\nis\nthe\nEiffel\nTower\nwith\nfireworks\nin\nthe\nbackground\n...\n//\n//\nContent\nwritten\nto\n:\nresources\n/\noutput\n/\nexample\n-\nimage\n-\neiffel\n-\ntower\n.\npng\n}\n}\n}\nImage understanding\nGemini can understand images as well. The following code uses the image\ngenerated in the previous section and uses a different model to infer\ninformation about the image:\nPython\nfrom\ngoogle\nimport\ngenai\nfrom\ngoogle.genai.types\nimport\nHttpOptions\n,\nPart\nclient\n=\ngenai\n.\nClient\n(\nhttp_options\n=\nHttpOptions\n(\napi_version\n=\n\"v1\"\n))\nresponse\n=\nclient\n.\nmodels\n.\ngenerate_content\n(\nmodel\n=\n\"gemini-2.5-flash\"\n,\ncontents\n=\n[\n\"What is shown in this image?\"\n,\nPart\n.\nfrom_uri\n(\nfile_uri\n=\n\"gs://cloud-samples-data/generative-ai/image/scones.jpg\"\n,\nmime_type\n=\n\"image/jpeg\"\n,\n),\n],\n)\nprint\n(\nresponse\n.\ntext\n)\n# Example response:\n# The image shows a flat lay of blueberry scones arranged on parchment paper. There are ...\nGo\nimport\n(\n\"context\"\n\"fmt\"\n\"io\"\ngenai\n\"google.golang.org/genai\"\n)\n//\ngenerateWithTextImage\nshows\nhow\nto\ngenerate\ntext\nusing\nboth\ntext\nand\nimage\ninput\nfunc\ngenerateWithTextImage\n(\nw\nio\n.\nWriter\n)\nerror\n{\nctx\n:=\ncontext\n.\nBackground\n()\nclient\n,\nerr\n:=\ngenai\n.\nNewClient\n(\nctx\n,\n&\ngenai\n.\nClientConfig\n{\nHTTPOptions\n:\ngenai\n.\nHTTPOptions\n{\nAPIVersion\n:\n\"v1\"\n},\n})\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to create genai client: %w\"\n,\nerr\n)\n}\nmodelName\n:=\n\"gemini-2.5-flash\"\ncontents\n:=\n[]\n*\ngenai\n.\nContent\n{\n{\nParts\n:\n[]\n*\ngenai\n.\nPart\n{\n{\nText\n:\n\"What is shown in this image?\"\n},\n{\nFileData\n:\n&\ngenai\n.\nFileData\n{\n//\nImage\nsource\n:\nhttps\n:\n//\nstorage\n.\ngoogleapis\n.\ncom\n/\ncloud\n-\nsamples\n-\ndata\n/\ngenerative\n-\nai\n/\nimage\n/\nscones\n.\njpg\nFileURI\n:\n\"gs://cloud-samples-data/generative-ai/image/scones.jpg\"\n,\nMIMEType\n:\n\"image/jpeg\"\n,\n}},\n},\nRole\n:\n\"user\"\n},\n}\nresp\n,\nerr\n:=\nclient\n.\nModels\n.\nGenerateContent\n(\nctx\n,\nmodelName\n,\ncontents\n,\nnil\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to generate content: %w\"\n,\nerr\n)\n}\nrespText\n:=\nresp\n.\nText\n()\nfmt\n.\nFprintln\n(\nw\n,\nrespText\n)\n//\nExample\nresponse\n:\n//\nThe\nimage\nshows\nan\noverhead\nshot\nof\na\nrustic\n,\nartistic\narrangement\non\na\nsurface\nthat\n...\nreturn\nnil\n}\nNode.js\nconst\n{\nGoogleGenAI\n}\n=\nrequire\n(\n'@google/genai'\n);\nconst\nGOOGLE_CLOUD_PROJECT\n=\nprocess\n.\nenv\n.\nGOOGLE_CLOUD_PROJECT\n;\nconst\nGOOGLE_CLOUD_LOCATION\n=\nprocess\n.\nenv\n.\nGOOGLE_CLOUD_LOCATION\n||\n'global'\n;\nasync\nfunction\ngenerateContent\n(\nprojectId\n=\nGOOGLE_CLOUD_PROJECT\n,\nlocation\n=\nGOOGLE_CLOUD_LOCATION\n)\n{\nconst\nclient\n=\nnew\nGoogleGenAI\n({\nvertexai\n:\ntrue\n,\nproject\n:\nprojectId\n,\nlocation\n:\nlocation\n,\n});\nconst\nimage\n=\n{\nfileData\n:\n{\nfileUri\n:\n'gs://cloud-samples-data/generative-ai/image/scones.jpg'\n,\nmimeType\n:\n'image/jpeg'\n,\n},\n};\nconst\nresponse\n=\nawait\nclient\n.\nmodels\n.\ngenerateContent\n({\nmodel\n:\n'gemini-2.5-flash'\n,\ncontents\n:\n[\nimage\n,\n'What is shown in this image?'\n],\n});\nconsole\n.\nlog\n(\nresponse\n.\ntext\n);\nreturn\nresponse\n.\ntext\n;\n}\nJava\nimport\ncom.google.genai.Client\n;\nimport\ncom.google.genai.types.Content\n;\nimport\ncom.google.genai.types.GenerateContentResponse\n;\nimport\ncom.google.genai.types.HttpOptions\n;\nimport\ncom.google.genai.types.Part\n;\npublic\nclass\nTextGenerationWithTextAndImage\n{\npublic\nstatic\nvoid\nmain\n(\nString\n[]\nargs\n)\n{\n//\nTODO\n(\ndeveloper\n):\nReplace\nthese\nvariables\nbefore\nrunning\nthe\nsample\n.\nString\nmodelId\n=\n\"gemini-2.5-flash\"\n;\ngenerateContent\n(\nmodelId\n);\n}\n//\nGenerates\ntext\nwith\ntext\nand\nimage\ninput\npublic\nstatic\nString\ngenerateContent\n(\nString\nmodelId\n)\n{\n//\nInitialize\nclient\nthat\nwill\nbe\nused\nto\nsend\nrequests\n.\nThis\nclient\nonly\nneeds\nto\nbe\ncreated\n//\nonce\n,\nand\ncan\nbe\nreused\nfor\nmultiple\nrequests\n.\ntry\n(\nClient\nclient\n=\nClient\n.\nbuilder\n()\n.\nlocation\n(\n\"global\"\n)\n.\nvertexAI\n(\ntrue\n)\n.\nhttpOptions\n(\nHttpOptions\n.\nbuilder\n()\n.\napiVersion\n(\n\"v1\"\n)\n.\nbuild\n())\n.\nbuild\n())\n{\nGenerateContentResponse\nresponse\n=\nclient\n.\nmodels\n.\ngenerateContent\n(\nmodelId\n,\nContent\n.\nfromParts\n(\nPart\n.\nfromText\n(\n\"What is shown in this image?\"\n),\nPart\n.\nfromUri\n(\n\"gs://cloud-samples-data/generative-ai/image/scones.jpg\"\n,\n\"image/jpeg\"\n)),\nnull\n);\nSystem\n.\nout\n.\nprint\n(\nresponse\n.\ntext\n());\n//\nExample\nresponse\n:\n//\nThe\nimage\nshows\na\nflat\nlay\nof\nblueberry\nscones\narranged\non\nparchment\npaper\n.\nThere\nare\n...\nreturn\nresponse\n.\ntext\n();\n}\n}\n}\nCode execution\nThe Gemini API in Vertex AI code execution feature enables the model to generate and\nrun Python code and learn iteratively from the results until it arrives at a\nfinal output. Vertex AI provides code execution as a tool, similar to\nfunction calling. You can use this code execution capability to build\napplications that benefit from code-based reasoning and that produce text\noutput. For example:\nPython\nfrom\ngoogle\nimport\ngenai\nfrom\ngoogle.genai.types\nimport\n(\nHttpOptions\n,\nTool\n,\nToolCodeExecution\n,\nGenerateContentConfig\n,\n)\nclient\n=\ngenai\n.\nClient\n(\nhttp_options\n=\nHttpOptions\n(\napi_version\n=\n\"v1\"\n))\nmodel_id\n=\n\"gemini-2.5-flash\"\ncode_execution_tool\n=\nTool\n(\ncode_execution\n=\nToolCodeExecution\n())\nresponse\n=\nclient\n.\nmodels\n.\ngenerate_content\n(\nmodel\n=\nmodel_id\n,\ncontents\n=\n\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\"\n,\nconfig\n=\nGenerateContentConfig\n(\ntools\n=\n[\ncode_execution_tool\n],\ntemperature\n=\n0\n,\n),\n)\nprint\n(\n\"# Code:\"\n)\nprint\n(\nresponse\n.\nexecutable_code\n)\nprint\n(\n\"# Outcome:\"\n)\nprint\n(\nresponse\n.\ncode_execution_result\n)\n# Example response:\n# # Code:\n# def fibonacci(n):\n#     if n <= 0:\n#         return 0\n#     elif n == 1:\n#         return 1\n#     else:\n#         a, b = 0, 1\n#         for _ in range(2, n + 1):\n#             a, b = b, a + b\n#         return b\n#\n# fib_20 = fibonacci(20)\n# print(f'{fib_20=}')\n#\n# # Outcome:\n# fib_20=6765\nGo\nimport\n(\n\"context\"\n\"fmt\"\n\"io\"\ngenai\n\"google.golang.org/genai\"\n)\n//\ngenerateWithCodeExec\nshows\nhow\nto\ngenerate\ntext\nusing\nthe\ncode\nexecution\ntool\n.\nfunc\ngenerateWithCodeExec\n(\nw\nio\n.\nWriter\n)\nerror\n{\nctx\n:=\ncontext\n.\nBackground\n()\nclient\n,\nerr\n:=\ngenai\n.\nNewClient\n(\nctx\n,\n&\ngenai\n.\nClientConfig\n{\nHTTPOptions\n:\ngenai\n.\nHTTPOptions\n{\nAPIVersion\n:\n\"v1\"\n},\n})\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to create genai client: %w\"\n,\nerr\n)\n}\nprompt\n:=\n\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\"\ncontents\n:=\n[]\n*\ngenai\n.\nContent\n{\n{\nParts\n:\n[]\n*\ngenai\n.\nPart\n{\n{\nText\n:\nprompt\n},\n},\nRole\n:\n\"user\"\n},\n}\nconfig\n:=\n&\ngenai\n.\nGenerateContentConfig\n{\nTools\n:\n[]\n*\ngenai\n.\nTool\n{\n{\nCodeExecution\n:\n&\ngenai\n.\nToolCodeExecution\n{}},\n},\nTemperature\n:\ngenai\n.\nPtr\n(\nfloat32\n(\n0.0\n)),\n}\nmodelName\n:=\n\"gemini-2.5-flash\"\nresp\n,\nerr\n:=\nclient\n.\nModels\n.\nGenerateContent\n(\nctx\n,\nmodelName\n,\ncontents\n,\nconfig\n)\nif\nerr\n!=\nnil\n{\nreturn\nfmt\n.\nErrorf\n(\n\"failed to generate content: %w\"\n,\nerr\n)\n}\nfor\n_\n,\np\n:=\nrange\nresp\n.\nCandidates\n[\n0\n]\n.\nContent\n.\nParts\n{\nif\np\n.\nText\n!=\n\"\"\n{\nfmt\n.\nFprintf\n(\nw\n,\n\"Gemini:\n%s\n\"\n,\np\n.\nText\n)\n}\nif\np\n.\nExecutableCode\n!=\nnil\n{\nfmt\n.\nFprintf\n(\nw\n,\n\"Language:\n%s\n\\n\n%s\n\\n\n\"\n,\np\n.\nExecutableCode\n.\nLanguage\n,\np\n.\nExecutableCode\n.\nCode\n)\n}\nif\np\n.\nCodeExecutionResult\n!=\nnil\n{\nfmt\n.\nFprintf\n(\nw\n,\n\"Outcome:\n%s\n\\n\n%s\n\\n\n\"\n,\np\n.\nCodeExecutionResult\n.\nOutcome\n,\np\n.\nCodeExecutionResult\n.\nOutput\n)\n}\n}\n//\nExample\nresponse\n:\n//\nGemini\n:\nOkay\n,\nI\ncan\ndo\nthat\n.\nFirst\n,\nI\n'll calculate the 20th Fibonacci number. Then, I need ...\n//\n//\nLanguage\n:\nPYTHON\n//\n//\ndef\nfibonacci\n(\nn\n):\n//\n...\n//\n//\nfib_20\n=\nfibonacci\n(\n20\n)\n//\nprint\n(\nf\n'\n{\nfib_20\n=}\n'\n)\n//\n//\nOutcome\n:\nOUTCOME_OK\n//\nfib_20\n=\n6765\n//\n//\nNow\nthat\nI\nhave\nthe\n20\nth\nFibonacci\nnumber\n(\n6765\n),\nI\nneed\nto\nfind\nthe\nnearest\npalindrome\n.\n...\n//\n...\nreturn\nnil\n}\nNode.js\nconst\n{\nGoogleGenAI\n}\n=\nrequire\n(\n'@google/genai'\n);\nconst\nGOOGLE_CLOUD_PROJECT\n=\nprocess\n.\nenv\n.\nGOOGLE_CLOUD_PROJECT\n;\nconst\nGOOGLE_CLOUD_LOCATION\n=\nprocess\n.\nenv\n.\nGOOGLE_CLOUD_LOCATION\n||\n'global'\n;\nasync\nfunction\ngenerateAndExecuteCode\n(\nprojectId\n=\nGOOGLE_CLOUD_PROJECT\n,\nlocation\n=\nGOOGLE_CLOUD_LOCATION\n)\n{\nconst\nclient\n=\nnew\nGoogleGenAI\n({\nvertexai\n:\ntrue\n,\nproject\n:\nprojectId\n,\nlocation\n:\nlocation\n,\n});\nconst\nresponse\n=\nawait\nclient\n.\nmodels\n.\ngenerateContent\n({\nmodel\n:\n'gemini-2.5-flash'\n,\ncontents\n:\n'Calculate 20th fibonacci number. Then find the nearest palindrome to it.'\n,\nconfig\n:\n{\ntools\n:\n[{\ncodeExecution\n:\n{}}],\ntemperature\n:\n0\n,\n},\n});\nconsole\n.\ndebug\n(\nresponse\n.\nexecutableCode\n);\n//\nExample\nresponse\n:\n//\nCode\n:\n//\nfunction\nfibonacci\n(\nn\n)\n{\n//\nif\n(\nn\n<\n=\n0\n)\n{\n//\nreturn\n0\n;\n//\n}\nelse\nif\n(\nn\n===\n1\n)\n{\n//\nreturn\n1\n;\n//\n}\nelse\n{\n//\nlet\na\n=\n0\n,\nb\n=\n1\n;\n//\nfor\n(\nlet\ni\n=\n2\n;\ni\n<\n=\nn\n;\ni\n++\n)\n{\n//\n[\na\n,\nb\n]\n=\n[\nb\n,\na\n+\nb\n];\n//\n}\n//\nreturn\nb\n;\n//\n}\n//\n}\n//\n//\nconst\nfib20\n=\nfibonacci\n(\n20\n);\n//\nconsole\n.\nlog\n(\n`\nfib20\n=$\n{\nfib20\n}\n`\n);\nconsole\n.\ndebug\n(\nresponse\n.\ncodeExecutionResult\n);\n//\nOutcome\n:\n//\nfib20\n=\n6765\nreturn\nresponse\n.\ncodeExecutionResult\n;\n}\nJava\nimport\ncom.google.genai.Client\n;\nimport\ncom.google.genai.types.GenerateContentConfig\n;\nimport\ncom.google.genai.types.GenerateContentResponse\n;\nimport\ncom.google.genai.types.HttpOptions\n;\nimport\ncom.google.genai.types.Tool\n;\nimport\ncom.google.genai.types.ToolCodeExecution\n;\npublic\nclass\nToolsCodeExecWithText\n{\npublic\nstatic\nvoid\nmain\n(\nString\n[]\nargs\n)\n{\n//\nTODO\n(\ndeveloper\n):\nReplace\nthese\nvariables\nbefore\nrunning\nthe\nsample\n.\nString\nmodelId\n=\n\"gemini-2.5-flash\"\n;\ngenerateContent\n(\nmodelId\n);\n}\n//\nGenerates\ntext\nusing\nthe\nCode\nExecution\ntool\npublic\nstatic\nString\ngenerateContent\n(\nString\nmodelId\n)\n{\n//\nInitialize\nclient\nthat\nwill\nbe\nused\nto\nsend\nrequests\n.\nThis\nclient\nonly\nneeds\nto\nbe\ncreated\n//\nonce\n,\nand\ncan\nbe\nreused\nfor\nmultiple\nrequests\n.\ntry\n(\nClient\nclient\n=\nClient\n.\nbuilder\n()\n.\nlocation\n(\n\"global\"\n)\n.\nvertexAI\n(\ntrue\n)\n.\nhttpOptions\n(\nHttpOptions\n.\nbuilder\n()\n.\napiVersion\n(\n\"v1\"\n)\n.\nbuild\n())\n.\nbuild\n())\n{\n//\nCreate\na\nGenerateContentConfig\nand\nset\ncodeExecution\ntool\nGenerateContentConfig\ncontentConfig\n=\nGenerateContentConfig\n.\nbuilder\n()\n.\ntools\n(\nTool\n.\nbuilder\n()\n.\ncodeExecution\n(\nToolCodeExecution\n.\nbuilder\n()\n.\nbuild\n())\n.\nbuild\n())\n.\ntemperature\n(\n0.0\nF\n)\n.\nbuild\n();\nGenerateContentResponse\nresponse\n=\nclient\n.\nmodels\n.\ngenerateContent\n(\nmodelId\n,\n\"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\"\n,\ncontentConfig\n);\nSystem\n.\nout\n.\nprintln\n(\n\"Code:\n\\n\n\"\n+\nresponse\n.\nexecutableCode\n());\nSystem\n.\nout\n.\nprintln\n(\n\"Outcome:\n\\n\n\"\n+\nresponse\n.\ncodeExecutionResult\n());\n//\nExample\nresponse\n//\nCode\n:\n//\ndef\nfibonacci\n(\nn\n):\n//\nif\nn\n<\n=\n0\n:\n//\nreturn\n0\n//\nelif\nn\n==\n1\n:\n//\nreturn\n1\n//\nelse\n:\n//\na\n,\nb\n=\n1\n,\n1\n//\nfor\n_\nin\nrange\n(\n2\n,\nn\n):\n//\na\n,\nb\n=\nb\n,\na\n+\nb\n//\nreturn\nb\n//\n//\nfib_20\n=\nfibonacci\n(\n20\n)\n//\nprint\n(\nf\n'\n{\nfib_20\n=}\n'\n)\n//\n//\nOutcome\n:\n//\nfib_20\n=\n6765\nreturn\nresponse\n.\nexecutableCode\n();\n}\n}\n}\nFor more examples of code execution, check out the\ncode execution\ndocumentation\n.\nWhat's next\nNow that you made your first API request, you might want to explore the\nfollowing guides that show how to set up more advanced Vertex AI\nfeatures for production code:\nGoogle Gen AI libraries\nOpenAI compatibility\nSend feedback\nExcept as otherwise noted, the content of this page is licensed under the\nCreative Commons Attribution 4.0 License\n, and code samples are licensed under the\nApache 2.0 License\n. For details, see the\nGoogle Developers Site Policies\n. Java is a registered trademark of Oracle and/or its affiliates.\nLast updated 2025-11-07 UTC.",
  "metadata": {
    "title": "Gemini API in Vertex AI quickstart  |  Generative AI on Vertex AI  |  Google Cloud Documentation",
    "extracted_at": "2025-11-11 14:26:51"
  }
}