{
  "url": "https://docs.cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-vertex-ai-search",
  "title": "Grounding with Vertex AI Search  |  Generative AI on Vertex AI  |  Google Cloud Documentation",
  "text_content": "Home\nTechnology areas\nGenerative AI on Vertex AI\nDocumentation\nSend feedback\nGrounding with Vertex AI Search\nStay organized with collections\nSave and categorize content based on your preferences.\nThis page explains how you can ground responses by using your data from\nVertex AI Search.\nGrounding Gemini to your data\nIf you want to do retrieval-augmented generation (RAG), connect your model to\nyour website data or your sets of documents, then use\nGrounding with\nVertex AI Search\n.\nGrounding to your data supports a maximum of 10 Vertex AI Search\ndata sources and can be combined with\nGrounding with\nGoogle Search\n.\nSupported models\nThis section lists the models that support grounding with your data.\nGemini 2.5 Flash\n(Preview)\nGemini 2.5 Flash-Lite\n(Preview)\nGemini 2.5 Flash-Lite\nGemini 2.5 Flash with Live API native audio\n(Preview)\nGemini 2.0 Flash with Live API\n(Preview)\nGemini 2.5 Pro\nGemini 2.5 Flash\nGemini 2.0 Flash\nPrerequisites\nBefore you can ground model output to your data, do the following:\nIn the Google Cloud console, go to the\nIAM\npage, and search for the\ndiscoveryengine.servingConfigs.search\npermission, which is required for the\ngrounding service to work.\nGo to IAM\nEnable AI Applications\nand activate the API.\nCreate a AI Applications data source\nand\napplication.\nSee the\nIntroduction to Vertex AI Search\nfor more.\nEnable AI Applications\nTo use Vertex AI Search to ground your responses, you must activate the\nVertex AI Search service by following these steps:\nIn the Google Cloud console, go to the\nAI Applications\npage.\nGo to AI Applications\nOptional: Review the\nterms for data use\n.\nAI Applications is available in the\nglobal\nlocation or the\neu\nand\nus\nmulti-region. To learn more, see\nAI Applications\nlocations\n.\nCreate a data store in AI Applications\nTo create a data store in AI Applications, you can choose to\nground with website data or documents.\nWebsite\nOpen the\nCreate Data\nStore\npage from the Google Cloud console.\nIn\nWebsite Content\nbox, click\nSelect\n.\nSpecify the\nwebsites for your data store\npane displays.\nIf\nAdvanced website indexing\nisn't checked, then select the\nAdvanced\nwebsite indexing\ncheckbox to turn it on.\nConfigure your data store\npane displays.\nIn the\nSpecify URL patterns to index\nsection, do the following:\nAdd URLs for\nSites to include\n.\nOptional: Add URLs for\nSites to exclude\n.\nClick\nContinue\n.\nIn the\nConfigure your data store\npane,\nSelect a value from the\nLocation of your data store\nlist.\nEnter a name in the\nYour data store name\nfield. The ID is\ngenerated. Use this ID when you generate your grounded responses with\nyour data store. For more information, see\nGenerate grounded responses\nwith your data store\n.\nClick\nCreate\n.\nDocuments\nOpen the\nCreate Data\nStore\npage from the Google Cloud console.\nIn\nCloud Storage\nbox, click\nSelect\n.\nImport data from\nCloud Storage\npane displays.\nIn the\nUnstructured documents (PDF, HTML, TXT and more)\nsection, select\nUnstructured documents (PDF, HTML, TXT and more)\n.\nSelect a\nSynchronization frequency\noption.\nSelect a\nSelect a folder or a file you want to import\noption, and\nenter the path in the field.\nClick\nContinue\n.\nConfigure your data store\npane displays.\nIn the\nConfigure your data store\npane,\nSelect a value from the\nLocation of your data store\nlist.\nEnter a name in the\nYour data store name\nfield. The ID is\ngenerated.\nTo select parsing and chunking options for your documents, expand the\nDocument Processing Options\nsection. For more information about\ndifferent parsers, see\nParse\ndocuments\n.\nClick\nCreate\n.\nClick\nCreate\n.\nGenerate grounded responses with your data store\nUse the following instructions to ground a model with your data. A maximum\nof 10 data stores is supported.\nIf you don't know your data store ID, follow these steps:\nIn the Google Cloud console, go to the\nAI Applications\npage and\nin the navigation menu, click\nData stores\n.\nGo to the Data stores page\nClick the name of your data store.\nOn the\nData\npage for your data store, get the data store ID.\nConsole\nTo ground your model output to AI Applications by using Vertex AI Studio in the\nGoogle Cloud console, follow these steps:\nIn the Google Cloud console, go to the\nVertex AI Studio Freeform\npage.\nGo to\nFreeform\nTo turn on grounding, click the\nGrounding: your data\ntoggle.\nClick\nCustomize\n.\nSelect\nVertex AI Search\nas your source.\nUsing this path format, replace your data store's Project ID and\nthe ID of the data store:\nprojects/\nPROJECT_ID\n/locations/global/collections/default_collection/dataStores/\nDATASTORE_ID\n.\nClick\nSave\n.\nEnter your prompt in the text box, and click\nSubmit\n.\nYour prompt responses are grounded to AI Applications.\nPython\nInstall\npip install --upgrade google-genai\nTo learn more, see the\nSDK reference documentation\n.\nSet environment variables to use the Gen AI SDK with Vertex AI:\n# Replace the `GOOGLE_CLOUD_PROJECT` and `GOOGLE_CLOUD_LOCATION` values\n# with appropriate values for your project.\nexport\nGOOGLE_CLOUD_PROJECT\n=\nGOOGLE_CLOUD_PROJECT\nexport\nGOOGLE_CLOUD_LOCATION\n=\nglobal\nexport\nGOOGLE_GENAI_USE_VERTEXAI\n=\nTrue\nfrom\ngoogle\nimport\ngenai\nfrom\ngoogle.genai.types\nimport\n(\nGenerateContentConfig\n,\nVertexAISearch\n,\nRetrieval\n,\nTool\n,\nHttpOptions\n,\n)\nclient\n=\ngenai\n.\nClient\n(\nhttp_options\n=\nHttpOptions\n(\napi_version\n=\n\"v1\"\n))\n# Replace with your Vertex AI Search data store details\nDATASTORE_PATH\n=\n\"projects/\nPROJECT_ID\n/locations/global/collections/default_collection/dataStores/DATASTORE_ID\"\ntool\n=\nTool\n(\nretrieval\n=\nRetrieval\n(\nvertex_ai_search\n=\nVertexAISearch\n(\ndatastore\n=\nDATASTORE_PATH\n)\n)\n)\nresponse\n=\nclient\n.\nmodels\n.\ngenerate_content\n(\nmodel\n=\n\"gemini-2.5-flash\"\n,\n# Or another supported model\ncontents\n=\n\"What information can you find about topic X in the provided documents?\"\n,\n# Your query\nconfig\n=\nGenerateContentConfig\n(\ntools\n=\n[\ntool\n],\n),\n)\nprint\n(\nresponse\n.\ntext\n)\nREST\nTo test a text prompt by using the Vertex AI API, send a POST request to the\npublisher model endpoint.\nBefore using any of the request data,\nmake the following replacements:\nLOCATION\n: The region to process the request. To use the\nglobal\nendpoint\n, exclude the location from the endpoint name, and configure the location of the resource to\nglobal\n.\nPROJECT_ID\n: Your\nproject ID\n.\nMODEL_ID\n: The model ID of the multimodal model.\nPROMPT\n: The prompt to send to the model.\nHTTP method and URL:\nPOST https://\nLOCATION\n-aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/\nLOCATION\n/publishers/google/models/\nMODEL_ID\n:generateContent\nRequest JSON body:\n{\n\"contents\": [{\n\"role\": \"user\",\n\"parts\": [{\n\"text\": \"\nPROMPT\n\"\n}]\n}],\n\"tools\": [{\n\"retrieval\": {\n\"vertexAiSearch\": {\n\"datastore\": projects/\nPROJECT_ID\n/locations/global/collections/default_collection/dataStores/\nDATASTORE_ID\n}\n}\n}],\n\"model\": \"projects/\nPROJECT_ID\n/locations/\nLOCATION\n/publishers/google/models/\nMODEL_ID\n\"\n}\nTo send your request, expand one of these options:\ncurl (Linux, macOS, or Cloud Shell)\nSave the request body in a file named\nrequest.json\n,\nand execute the following command:\ncurl -X POST \\\n-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n-H \"Content-Type: application/json; charset=utf-8\" \\\n-d @request.json \\\n\"https://\nLOCATION\n-aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/\nLOCATION\n/publishers/google/models/\nMODEL_ID\n:generateContent\"\nPowerShell (Windows)\nSave the request body in a file named\nrequest.json\n,\nand execute the following command:\n$cred = gcloud auth print-access-token\n$headers = @{ \"Authorization\" = \"Bearer $cred\" }\nInvoke-WebRequest `\n-Method POST `\n-Headers $headers `\n-ContentType: \"application/json; charset=utf-8\" `\n-InFile request.json `\n-Uri \"https://\nLOCATION\n-aiplatform.googleapis.com/v1beta1/projects/\nPROJECT_ID\n/locations/\nLOCATION\n/publishers/google/models/\nMODEL_ID\n:generateContent\" | Select-Object -Expand Content\nYou should receive a JSON response similar to the following:\n{\n\"candidates\": [\n{\n\"content\": {\n\"role\": \"model\",\n\"parts\": [\n{\n\"text\": \"You can make an appointment on the website https://dmv.gov/\"\n}\n]\n},\n\"finishReason\": \"STOP\",\n\"safetyRatings\": [\n\"...\"\n],\n\"groundingMetadata\": {\n\"retrievalQueries\": [\n\"How to make appointment to renew driving license?\"\n],\n\"groundingChunks\": [\n{\n\"retrievedContext\": {\n\"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AXiHM.....QTN92V5ePQ==\",\n\"title\": \"dmv\"\n}\n}\n],\n\"groundingSupport\": [\n{\n\"segment\": {\n\"startIndex\": 25,\n\"endIndex\": 147\n},\n\"segment_text\": \"ipsum lorem ...\",\n\"supportChunkIndices\": [1, 2],\n\"confidenceScore\": [0.9541752, 0.97726375]\n},\n{\n\"segment\": {\n\"startIndex\": 294,\n\"endIndex\": 439\n},\n\"segment_text\": \"ipsum lorem ...\",\n\"supportChunkIndices\": [1],\n\"confidenceScore\": [0.9541752, 0.9325467]\n}\n]\n}\n}\n],\n\"usageMetadata\": {\n\"...\"\n}\n}\nUnderstand your response\nThe response from both APIs include the LLM-generated text, which is called a\ncandidate\n. If your model prompt successfully grounds to your data source, then\nthe responses include grounding metadata, which identifies the parts of the\nresponse that were derived from your data. However, there are several reasons\nthis metadata may not be provided, and the prompt response won't be grounded.\nThese reasons include low-source relevance or incomplete information within the\nmodel's response.\nThe following is a breakdown of the output data:\nRole\n: Indicates the sender of the grounded answer. Because the response\nalways contains grounded text, the role is always\nmodel\n.\nText\n: The grounded answer generated by the LLM.\nGrounding metadata\n: Information about the grounding source, which contains\nthe following elements:\nGrounding chunks\n: A list of results from your index that support the\nanswer.\nGrounding supports\n: Information about a specific claim within the answer\nthat can be used to show citations:\nSegment\n: The part of the model's answer that is substantiated by a\ngrounding chunk.\nGrounding chunk index\n: The index of the grounding chunks in the\ngrounding chunks list that corresponds to this claim.\nConfidence scores\n: A number from 0 to 1 that indicates how grounded\nthe claim is in the provided set of grounding chunks. Not available for\nGemini 2.5 and later.\nWhat's next\nTo learn how to send chat prompt requests, see\nMultiturn chat\n.\nTo learn about responsible AI best practices and Vertex AI's safety filters,\nsee\nSafety best practices\n.\nSend feedback\nExcept as otherwise noted, the content of this page is licensed under the\nCreative Commons Attribution 4.0 License\n, and code samples are licensed under the\nApache 2.0 License\n. For details, see the\nGoogle Developers Site Policies\n. Java is a registered trademark of Oracle and/or its affiliates.\nLast updated 2025-11-07 UTC.",
  "metadata": {
    "title": "Grounding with Vertex AI Search  |  Generative AI on Vertex AI  |  Google Cloud Documentation",
    "extracted_at": "2025-11-11 14:27:45"
  }
}